<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  
  <title><![CDATA[Anste]]></title>
  <subtitle><![CDATA[A Next Step To Extreme]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="http://www.anste.com//"/>
  <updated>2015-07-06T05:33:33.622Z</updated>
  <id>http://www.anste.com//</id>
  
  <author>
    <name><![CDATA[Anste]]></name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[【转载】Ceph常用运维命令]]></title>
    <link href="http://www.anste.com/2015/07/06/Ceph/"/>
    <id>http://www.anste.com/2015/07/06/Ceph/</id>
    <published>2015-07-06T03:42:18.000Z</published>
    <updated>2015-07-06T05:33:33.622Z</updated>
    <content type="html"><![CDATA[<p>转自<a href="http://zhanguo1110.blog.51cto.com/5750817/1543032" target="_blank" rel="external">51CTO zhanguo1110的BLOG</a></p>
<h1 id="一、集群">一、集群</h1><h2 id="1、启动一个ceph_进程">1、启动一个ceph 进程</h2><p>启动mon进程<br>service ceph start  mon.node1<br>启动msd进程<br>service ceph start mds.node1<br>启动osd进程<br> service ceph start osd.0</p>
<h2 id="2、查看机器的监控状态">2、查看机器的监控状态</h2><p>[root@client ~]# ceph health<br>HEALTH_OK</p>
<h2 id="3、查看ceph的实时运行状态">3、查看ceph的实时运行状态</h2>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@client ~]# ceph -w&#10;    cluster be1756f2-54f7-4d8f-8790-820c82721f17&#10;     health HEALTH_OK&#10;     monmap e2: 3 mons at &#123;node1=10.240.240.211:6789/0,node2=10.240.240.212:6789/0,node3=10.240.240.213:6789/0&#125;, election epoch 294, quorum 0,1,2 node1,node2,node3&#10;     mdsmap e95: 1/1/1 up &#123;0=node2=up:active&#125;, 1 up:standby&#10;     osdmap e88: 3 osds: 3 up, 3 in&#10;      pgmap v1164: 448 pgs, 4 pools, 10003 MB data, 2520 objects&#10;            23617 MB used, 37792 MB / 61410 MB avail&#10;                 448 active+clean&#10;2014-06-30 00:48:28.756948 mon.0 [INF] pgmap v1163: 448 pgs: 448 active+clean; 10003 MB data, 23617 MB used, 37792 MB / 61410 MB avail</span><br></pre></td></tr></table></figure>
<h2 id="4、检查信息状态信息">4、检查信息状态信息</h2>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@client ~]# ceph -s&#10;    cluster be1756f2-54f7-4d8f-8790-820c82721f17&#10;     health HEALTH_OK&#10;     monmap e2: 3 mons at &#123;node1=10.240.240.211:6789/0,node2=10.240.240.212:6789/0,node3=10.240.240.213:6789/0&#125;, election epoch 294, quorum 0,1,2 node1,node2,node3&#10;     mdsmap e95: 1/1/1 up &#123;0=node2=up:active&#125;, 1 up:standby&#10;     osdmap e88: 3 osds: 3 up, 3 in&#10;      pgmap v1164: 448 pgs, 4 pools, 10003 MB data, 2520 objects&#10;            23617 MB used, 37792 MB / 61410 MB avail&#10;                 448 active+clean&#10;[root@client ~]#</span><br></pre></td></tr></table></figure>
<h2 id="5、查看ceph存储空间">5、查看ceph存储空间</h2>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@client ~]# ceph df&#10;GLOBAL:&#10;    SIZE       AVAIL      RAW USED     %RAW USED &#10;    61410M     37792M     23617M       38.46     &#10;POOLS:&#10;    NAME         ID     USED       %USED     OBJECTS &#10;    data         0      10000M     16.28     2500    &#10;    metadata     1      3354k      0         20      &#10;    rbd          2      0          0         0       &#10;    jiayuan      3      0          0         0       &#10;[root@client ~]#</span><br></pre></td></tr></table></figure>
<h2 id="6、删除一个节点的所有的ceph数据包">6、删除一个节点的所有的ceph数据包</h2><p>[root@node1 ~]# ceph-deploy purge node1<br>[root@node1 ~]# ceph-deploy purgedata node1</p>
<h2 id="7、创建用户">7、创建用户</h2><p>为ceph创建一个admin用户并为admin用户创建一个密钥，把密钥保存到/etc/ceph目录下：<br>ceph auth get-or-create client.admin mds ‘allow’ osd ‘allow <em>‘ mon ‘allow </em>‘ &gt; /etc/ceph/ceph.client.admin.keyring<br>或<br>ceph auth get-or-create client.admin mds ‘allow’ osd ‘allow <em>‘ mon ‘allow </em>‘ -o /etc/ceph/ceph.client.admin.keyring</p>
<h2 id="8、osd创建key">8、osd创建key</h2><p>为osd.0创建一个用户并创建一个key<br>ceph auth get-or-create osd.0 mon ‘allow rwx’ osd ‘allow *’ -o /var/lib/ceph/osd/ceph-0/keyring</p>
<h2 id="9、mds创建key">9、mds创建key</h2><p>为mds.node1创建一个用户并创建一个key<br>ceph auth get-or-create mds.node1 mon ‘allow rwx’ osd ‘allow <em>‘ mds ‘allow </em>‘ -o /var/lib/ceph/mds/ceph-node1/keyring</p>
<h2 id="10、查看ceph集群中的认证用户及相关的key">10、查看ceph集群中的认证用户及相关的key</h2><p>ceph auth list</p>
<h2 id="11、删除集群中的一个认证用户">11、删除集群中的一个认证用户</h2><p>ceph auth del osd.0</p>
<h2 id="12、查看集群的详细配置">12、查看集群的详细配置</h2><p>[root@node1 ~]# ceph daemon mon.node1 config show | more</p>
<h2 id="13、查看集群健康状态细节">13、查看集群健康状态细节</h2>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]# ceph health detail&#10;HEALTH_WARN 12 pgs down; 12 pgs peering; 12 pgs stuck inactive; 12 pgs stuck unclean&#10;pg 3.3b is stuck inactive since forever, current state down+peering, last acting [1,2]&#10;pg 3.36 is stuck inactive since forever, current state down+peering, last acting [1,2]&#10;pg 3.79 is stuck inactive since forever, current state down+peering, last acting [1,0]&#10;pg 3.5 is stuck inactive since forever, current state down+peering, last acting [1,2]&#10;pg 3.30 is stuck inactive since forever, current state down+peering, last acting [1,2]&#10;pg 3.1a is stuck inactive since forever, current state down+peering, last acting [1,0]&#10;pg 3.2d is stuck inactive since forever, current state down+peering, last acting [1,0]&#10;pg 3.16 is stuck inactive since forever, current state down+peering, last acting [1,2]</span><br></pre></td></tr></table></figure>
<h2 id="14、查看ceph_log日志所在的目录">14、查看ceph log日志所在的目录</h2><p>[root@node1 ~]# ceph-conf —name mon.node1 —show-config-value log_file<br>/var/log/ceph/ceph-mon.node1.log</p>
<h1 id="二、mon">二、mon</h1><h2 id="1、查看mon的状态信息">1、查看mon的状态信息</h2><p>[root@client ~]# ceph mon stat<br>e2: 3 mons at {node1=10.240.240.211:6789/0,node2=10.240.240.212:6789/0,node3=10.240.240.213:6789/0}, election epoch 294, quorum 0,1,2 node1,node2,node3</p>
<h2 id="2、查看mon的选举状态">2、查看mon的选举状态</h2>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@client ~]# ceph quorum_status&#10;&#123;&#34;election_epoch&#34;:294,&#34;quorum&#34;:[0,1,2],&#34;quorum_names&#34;:[&#34;node1&#34;,&#34;node2&#34;,&#34;node3&#34;],&#34;quorum_leader_name&#34;:&#34;node1&#34;,&#34;monmap&#34;:&#123;&#34;epoch&#34;:2,&#34;fsid&#34;:&#34;be1756f2-54f7-4d8f-8790-820c82721f17&#34;,&#34;modified&#34;:&#34;2014-06-26 18:43:51.671106&#34;,&#34;created&#34;:&#34;0.000000&#34;,&#34;mons&#34;:[&#123;&#34;rank&#34;:0,&#34;name&#34;:&#34;node1&#34;,&#34;addr&#34;:&#34;10.240.240.211:6789\/0&#34;&#125;,&#123;&#34;rank&#34;:1,&#34;name&#34;:&#34;node2&#34;,&#34;addr&#34;:&#34;10.240.240.212:6789\/0&#34;&#125;,&#123;&#34;rank&#34;:2,&#34;name&#34;:&#34;node3&#34;,&#34;addr&#34;:&#34;10.240.240.213:6789\/0&#34;&#125;]&#125;&#125;</span><br></pre></td></tr></table></figure>
<h2 id="3、查看mon的映射信息">3、查看mon的映射信息</h2>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@client ~]# ceph mon dump&#10;dumped monmap epoch 2&#10;epoch 2&#10;fsid be1756f2-54f7-4d8f-8790-820c82721f17&#10;last_changed 2014-06-26 18:43:51.671106&#10;created 0.000000&#10;0: 10.240.240.211:6789/0 mon.node1&#10;1: 10.240.240.212:6789/0 mon.node2&#10;2: 10.240.240.213:6789/0 mon.node3</span><br></pre></td></tr></table></figure>
<h2 id="4、删除一个mon节点">4、删除一个mon节点</h2><p>[root@node1 ~]# ceph mon remove node1<br>removed mon.node1 at 10.39.101.1:6789/0, there are now 3 monitors<br>2014-07-07 18:11:04.974188 7f4d16bfd700  0 monclient: hunting for new mon</p>
<h2 id="5、获得mon_map">5、获得mon map</h2><p>获得一个正在运行的mon map，并保存在1.txt文件中<br>[root@node3 ~]# ceph mon getmap -o 1.txt<br>got monmap epoch 6</p>
<h2 id="6、查看上面获得的map">6、查看上面获得的map</h2>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node3 ~]#  monmaptool --print 1.txt &#10;monmaptool: monmap file 1.txt&#10;epoch 6&#10;fsid 92552333-a0a8-41b8-8b45-c93a8730525e&#10;last_changed 2014-07-07 18:22:51.927205&#10;created 0.000000&#10;0: 10.39.101.1:6789/0 mon.node1&#10;1: 10.39.101.2:6789/0 mon.node2&#10;2: 10.39.101.3:6789/0 mon.node3&#10;[root@node3 ~]#</span><br></pre></td></tr></table></figure>
<h2 id="7、把上面的mon_map注入新加入的节点">7、把上面的mon map注入新加入的节点</h2><p>ceph-mon -i node4 —inject-monmap 1.txt</p>
<h2 id="8、查看mon的amin_socket">8、查看mon的amin socket</h2><p>root@node1 ~]# ceph-conf —name mon.node1 —show-config-value admin_socket<br>/var/run/ceph/ceph-mon.node1.asok </p>
<h2 id="9、查看mon的详细状态">9、查看mon的详细状态</h2>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# ceph daemon mon.node1  mon_status &#10;&#123; &#34;name&#34;: &#34;node1&#34;,&#10;  &#34;rank&#34;: 0,&#10;  &#34;state&#34;: &#34;leader&#34;,&#10;  &#34;election_epoch&#34;: 96,&#10;  &#34;quorum&#34;: [&#10;        0,&#10;        1,&#10;        2],&#10;  &#34;outside_quorum&#34;: [],&#10;  &#34;extra_probe_peers&#34;: [&#10;        &#34;10.39.101.4:6789\/0&#34;],&#10;  &#34;sync_provider&#34;: [],&#10;  &#34;monmap&#34;: &#123; &#34;epoch&#34;: 6,&#10;      &#34;fsid&#34;: &#34;92552333-a0a8-41b8-8b45-c93a8730525e&#34;,&#10;      &#34;modified&#34;: &#34;2014-07-07 18:22:51.927205&#34;,&#10;      &#34;created&#34;: &#34;0.000000&#34;,&#10;      &#34;mons&#34;: [&#10;            &#123; &#34;rank&#34;: 0,&#10;              &#34;name&#34;: &#34;node1&#34;,&#10;              &#34;addr&#34;: &#34;10.39.101.1:6789\/0&#34;&#125;,&#10;            &#123; &#34;rank&#34;: 1,&#10;              &#34;name&#34;: &#34;node2&#34;,&#10;              &#34;addr&#34;: &#34;10.39.101.2:6789\/0&#34;&#125;,&#10;            &#123; &#34;rank&#34;: 2,&#10;              &#34;name&#34;: &#34;node3&#34;,&#10;              &#34;addr&#34;: &#34;10.39.101.3:6789\/0&#34;&#125;]&#125;</span><br></pre></td></tr></table></figure>
<h2 id="10、删除一个mon节点">10、删除一个mon节点</h2><p>[root@os-node1 ~]# ceph mon remove os-node1<br>removed mon.os-node1 at 10.40.10.64:6789/0, there are now 3 monitors</p>
<h1 id="三、msd">三、msd</h1><h2 id="1、查看msd状态">1、查看msd状态</h2><p>[root@client ~]# ceph mds stat<br>e95: 1/1/1 up {0=node2=up:active}, 1 up:standby</p>
<h2 id="2、查看msd的映射信息">2、查看msd的映射信息</h2>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@client ~]# ceph mds dump&#10;dumped mdsmap epoch 95&#10;epoch   95&#10;flags   0&#10;created 2014-06-26 18:41:57.686801&#10;modified        2014-06-30 00:24:11.749967&#10;tableserver     0&#10;root    0&#10;session_timeout 60&#10;session_autoclose       300&#10;max_file_size   1099511627776&#10;last_failure    84&#10;last_failure_osd_epoch  81&#10;compat  compat=&#123;&#125;,rocompat=&#123;&#125;,incompat=&#123;1=base v0.20,2=client writeable ranges,3=default file layouts on dirs,4=dir inode in separate object,5=mds uses versioned encoding,6=dirfrag is stored in omap&#125;&#10;max_mds 1&#10;in      0&#10;up      &#123;0=5015&#125;&#10;failed&#10;stopped&#10;data_pools      0&#10;metadata_pool   1&#10;inline_data     disabled&#10;5015:   10.240.240.212:6808/3032 &#39;node2&#39; mds.0.12 up:active seq 30&#10;5012:   10.240.240.211:6807/3459 &#39;node1&#39; mds.-1.0 up:standby seq 38</span><br></pre></td></tr></table></figure>
<h2 id="3、删除一个mds节点">3、删除一个mds节点</h2><p>[root@node1 ~]# ceph  mds rm 0 mds.node1<br> mds gid 0 dne</p>
<h1 id="四、osd">四、osd</h1><h2 id="1、查看ceph_osd运行状态">1、查看ceph osd运行状态</h2><p>[root@client ~]# ceph osd stat<br>     osdmap e88: 3 osds: 3 up, 3 in</p>
<h2 id="2、查看osd映射信息">2、查看osd映射信息</h2>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@client ~]# ceph osd dump&#10;epoch 88&#10;fsid be1756f2-54f7-4d8f-8790-820c82721f17&#10;created 2014-06-26 18:41:57.687442&#10;modified 2014-06-30 00:46:27.179793&#10;flags &#10;pool 0 &#39;data&#39; replicated size 2 min_size 1 crush_ruleset 0 object_hash rjenkins pg_num 64 pgp_num 64 last_change 1 owner 0 flags hashpspool crash_replay_interval 45 stripe_width 0&#10;pool 1 &#39;metadata&#39; replicated size 2 min_size 1 crush_ruleset 0 object_hash rjenkins pg_num 64 pgp_num 64 last_change 1 owner 0 flags hashpspool stripe_width 0&#10;pool 2 &#39;rbd&#39; replicated size 2 min_size 1 crush_ruleset 0 object_hash rjenkins pg_num 64 pgp_num 64 last_change 1 owner 0 flags hashpspool stripe_width 0&#10;pool 3 &#39;jiayuan&#39; replicated size 2 min_size 1 crush_ruleset 0 object_hash rjenkins pg_num 256 pgp_num 256 last_change 73 owner 0 flags hashpspool stripe_width 0&#10;max_osd 3&#10;osd.0 up   in  weight 1 up_from 65 up_thru 75 down_at 64 last_clean_interval [53,55) 10.240.240.211:6800/3089 10.240.240.211:6801/3089 10.240.240.211:6802/3089 10.240.240.211:6803/3089 exists,up 8a24ad16-a483-4bac-a56a-6ed44ab74ff0&#10;osd.1 up   in  weight 1 up_from 59 up_thru 74 down_at 58 last_clean_interval [31,55) 10.240.240.212:6800/2696 10.240.240.212:6801/2696 10.240.240.212:6802/2696 10.240.240.212:6803/2696 exists,up 8619c083-0273-4203-ba57-4b1dabb89339&#10;osd.2 up   in  weight 1 up_from 62 up_thru 74 down_at 61 last_clean_interval [39,55) 10.240.240.213:6800/2662 10.240.240.213:6801/2662 10.240.240.213:6802/2662 10.240.240.213:6803/2662 exists,up f8107c04-35d7-4fb8-8c82-09eb885f0e58&#10;[root@client ~]#</span><br></pre></td></tr></table></figure>
<h2 id="3、查看osd的目录树">3、查看osd的目录树</h2>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@client ~]# ceph osd tree&#10;# id    weight  type name       up/down reweight&#10;-1      3       root default&#10;-2      1               host node1&#10;0       1                       osd.0   up      1&#10;-3      1               host node2&#10;1       1                       osd.1   up      1&#10;-4      1               host node3&#10;2       1                       osd.2   up      1</span><br></pre></td></tr></table></figure>
<h2 id="4、down掉一个osd硬盘">4、down掉一个osd硬盘</h2><p>[root@node1 ~]# ceph osd down 0   #down掉osd.0节点</p>
<h2 id="5、在集群中删除一个osd硬盘">5、在集群中删除一个osd硬盘</h2><p>[root@node4 ~]# ceph osd rm 0<br>removed osd.0</p>
<h2 id="6、在集群中删除一个osd_硬盘_crush_map">6、在集群中删除一个osd 硬盘 crush map</h2><p>[root@node1 ~]# ceph osd crush rm osd.0</p>
<h2 id="7、在集群中删除一个osd的host节点">7、在集群中删除一个osd的host节点</h2><p>[root@node1 ~]# ceph osd crush rm node1<br>removed item id -2 name ‘node1’ from crush map</p>
<p>查看最大osd的个数<br>[root@node1 ~]# ceph osd getmaxosd<br>max_osd = 4 in epoch 514           #默认最大是4个osd节点</p>
<h2 id="8、设置最大的osd的个数">8、设置最大的osd的个数</h2><p>（当扩大osd节点的时候必须扩大这个值）<br>[root@node1 ~]# ceph osd setmaxosd 10</p>
<h2 id="9、设置osd_crush的权重为1-0">9、设置osd crush的权重为1.0</h2><p>ceph osd crush set {id} {weight} [{loc1} [{loc2} …]]<br>例如：<br>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]# ceph osd crush set 3 3.0 host=node4&#10;set item id 3 name &#39;osd.3&#39; weight 3 at location &#123;host=node4&#125; to crush map&#10;[root@admin ~]# ceph osd tree&#10;# id    weight  type name       up/down reweight&#10;-1      6       root default&#10;-2      1               host node1&#10;0       1                       osd.0   up      1&#10;-3      1               host node2&#10;1       1                       osd.1   up      1&#10;-4      1               host node3&#10;2       1                       osd.2   up      1&#10;-5      3               host node4&#10;3       3                       osd.3   up      0.5</span><br></pre></td></tr></table></figure></p>
<p>或者用下面的方式<br>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]# ceph osd crush reweight osd.3 1.0&#10;reweighted item id 3 name &#39;osd.3&#39; to 1 in crush map&#10;[root@admin ~]# ceph osd tree&#10;# id    weight  type name       up/down reweight&#10;-1      4       root default&#10;-2      1               host node1&#10;0       1                       osd.0   up      1&#10;-3      1               host node2&#10;1       1                       osd.1   up      1&#10;-4      1               host node3&#10;2       1                       osd.2   up      1&#10;-5      1               host node4&#10;3       1                       osd.3   up      0.5</span><br></pre></td></tr></table></figure></p>
<h2 id="10、设置osd的权重">10、设置osd的权重</h2>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]# ceph osd reweight 3 0.5&#10;reweighted osd.3 to 0.5 (8327682)&#10;[root@admin ~]# ceph osd tree&#10;# id    weight  type name       up/down reweight&#10;-1      4       root default&#10;-2      1               host node1&#10;0       1                       osd.0   up      1&#10;-3      1               host node2&#10;1       1                       osd.1   up      1&#10;-4      1               host node3&#10;2       1                       osd.2   up      1&#10;-5      1               host node4&#10;3       1                       osd.3   up      0.5</span><br></pre></td></tr></table></figure>
<h2 id="11、把一个osd节点逐出集群">11、把一个osd节点逐出集群</h2>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]# ceph osd out osd.3&#10;marked out osd.3.  &#10;[root@admin ~]# ceph osd tree&#10;# id    weight  type name       up/down reweight&#10;-1      4       root default&#10;-2      1               host node1&#10;0       1                       osd.0   up      1&#10;-3      1               host node2&#10;1       1                       osd.1   up      1&#10;-4      1               host node3&#10;2       1                       osd.2   up      1&#10;-5      1               host node4&#10;3       1                       osd.3   up      0      # osd.3&#30340;reweight&#21464;&#20026;0&#20102;&#23601;&#19981;&#20877;&#20998;&#37197;&#25968;&#25454;&#65292;&#20294;&#26159;&#35774;&#22791;&#36824;&#26159;&#23384;&#27963;&#30340;</span><br></pre></td></tr></table></figure>
<h2 id="12、把逐出的osd加入集群">12、把逐出的osd加入集群</h2>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]# ceph osd in osd.3&#10;marked in osd.3. &#10;[root@admin ~]# ceph osd tree&#10;# id    weight  type name       up/down reweight&#10;-1      4       root default&#10;-2      1               host node1&#10;0       1                       osd.0   up      1&#10;-3      1               host node2&#10;1       1                       osd.1   up      1&#10;-4      1               host node3&#10;2       1                       osd.2   up      1&#10;-5      1               host node4&#10;3       1                       osd.3   up      1</span><br></pre></td></tr></table></figure>
<h2 id="13、暂停osd">13、暂停osd</h2><p> （暂停后整个集群不再接收数据）<br>[root@admin ~]# ceph osd pause<br>set pauserd,pausewr      </p>
<h2 id="14、再次开启osd">14、再次开启osd</h2><p> （开启后再次接收数据）<br>[root@admin ~]# ceph osd unpause<br>unset pauserd,pausewr</p>
<h2 id="15、查看一个集群osd-2参数的配置">15、查看一个集群osd.2参数的配置</h2><p>ceph —admin-daemon /var/run/ceph/ceph-osd.2.asok config show | less</p>
<h1 id="五、PG组">五、PG组</h1><h2 id="1、查看pg组的映射信息">1、查看pg组的映射信息</h2>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@client ~]# ceph pg dump&#10;dumped all in format plain&#10;version 1164&#10;stamp 2014-06-30 00:48:29.754714&#10;last_osdmap_epoch 88&#10;last_pg_scan 73&#10;full_ratio 0.95&#10;nearfull_ratio 0.85&#10;pg_stat objects mip     degr    unf     bytes   log     disklog state   state_stamp     v       reported       up      up_primary      acting  acting_primary  last_scrub      scrub_stamp     last_deep_scrudeep_scrub_stamp&#10;0.3f    39      0       0       0       163577856       128     128     active+clean    2014-06-30 00:30:59.193479     52&#39;128  88:242  [0,2]   0       [0,2]   0       44&#39;25   2014-06-29 22:25:25.282347    0&#39;0      2014-06-26 19:52:08.521434&#10;3.3c    0       0       0       0       0       0       0       active+clean    2014-06-30 00:15:38.675465     0&#39;0     88:21   [2,1]   2       [2,1]   2       0&#39;0     2014-06-30 00:15:04.295637      0&#39;0   2014-06-30 00:15:04.295637&#10;2.3c    0       0       0       0       0       0       0       active+clean    2014-06-30 00:10:48.583702     0&#39;0     88:46   [2,1]   2       [2,1]   2       0&#39;0     2014-06-29 22:29:13.701625      0&#39;0   2014-06-26 19:52:08.845944&#10;1.3f    2       0       0       0       452     2       2       active+clean    2014-06-30 00:10:48.596050     16&#39;2    88:66   [2,1]   2       [2,1]   2       16&#39;2    2014-06-29 22:28:03.570074      0&#39;0   2014-06-26 19:52:08.655292&#10;0.3e    31      0       0       0       130023424       130     130     active+clean    2014-06-30 00:26:22.803186     52&#39;130  88:304  [2,0]   2       [2,0]   2       44&#39;59   2014-06-29 22:26:41.317403    0&#39;0      2014-06-26 19:52:08.518978&#10;3.3d    0       0       0       0       0       0       0       active+clean    2014-06-30 00:16:57.548803     0&#39;0     88:20   [0,2]   0       [0,2]   0       0&#39;0     2014-06-30 00:15:19.101314      0&#39;0   2014-06-30 00:15:19.101314&#10;2.3f    0       0       0       0       0       0       0       active+clean    2014-06-30 00:10:58.750476     0&#39;0     88:106  [0,2]   0       [0,2]   0       0&#39;0     2014-06-29 22:27:44.604084      0&#39;0   2014-06-26 19:52:08.864240&#10;1.3c    1       0       0       0       0       1       1       active+clean    2014-06-30 00:10:48.939358     16&#39;1    88:66   [1,2]   1       [1,2]   1       16&#39;1    2014-06-29 22:27:35.991845      0&#39;0   2014-06-26 19:52:08.646470&#10;0.3d    34      0       0       0       142606336       149     149     active+clean    2014-06-30 00:23:57.348657     52&#39;149  88:300  [0,2]   0       [0,2]   0       44&#39;57   2014-06-29 22:25:24.279912    0&#39;0      2014-06-26 19:52:08.514526&#10;3.3e    0       0       0       0       0       0       0       active+clean    2014-06-30 00:15:39.554742     0&#39;0     88:21   [2,1]   2       [2,1]   2       0&#39;0     2014-06-30 00:15:04.296812      0&#39;0   2014-06-30 00:15:04.296812&#10;2.3e    0       0       0       0       0       0       0       active+clean    2014-06-30 00:10:48.592171     0&#39;0     88:46   [2,1]   2       [2,1]   2       0&#39;0     2014-06-29 22:29:14.702209      0&#39;0   2014-06-26 19:52:08.855382&#10;1.3d    0       0       0       0       0       0       0       active+clean    2014-06-30 00:10:48.938971     0&#39;0     88:58   [1,2]   1       [1,2]   1       0&#39;0     2014-06-29 22:27:36.971820      0&#39;0   2014-06-26 19:52:08.650070&#10;0.3c    41      0       0       0       171966464       157     157     active+clean    2014-06-30 00:24:55.751252     52&#39;157  88:385  [1,0]   1       [1,0]   1       44&#39;41   2014-06-29 22:26:34.829858    0&#39;0      2014-06-26 19:52:08.513798&#10;3.3f    0       0       0       0       0       0       0       active+clean    2014-06-30 00:17:08.416756     0&#39;0     88:20   [0,1]   0       [0,1]   0       0&#39;0     2014-06-30 00:15:19.406120      0&#39;0   2014-06-30 00:15:19.406120&#10;2.39    0       0       0       0       0       0       0       active+clean    2014-06-30 00:10:58.784789     0&#39;0     88:71   [2,0]   2       [2,0]   2       0&#39;0     2014-06-29 22:29:10.673549      0&#39;0   2014-06-26 19:52:08.834644&#10;1.3a    0       0       0       0       0       0       0       active+clean    2014-06-30 00:10:58.738782     0&#39;0     88:106  [0,2]   0       [0,2]   0       0&#39;0     2014-06-29 22:26:29.457318      0&#39;0   2014-06-26 19:52:08.642018&#10;0.3b    37      0       0       0       155189248       137     137     active+clean    2014-06-30 00:28:45.021993     52&#39;137  88:278  [0,2]   0       [0,2]   0       44&#39;40   2014-06-29 22:25:22.275783    0&#39;0      2014-06-26 19:52:08.510502&#10;3.38    0       0       0       0       0       0       0       active+clean    2014-06-30 00:16:13.222339     0&#39;0     88:21   [1,0]   1       [1,0]   1       0&#39;0     2014-06-30 00:15:05.446639      0&#39;0   2014-06-30 00:15:05.446639&#10;2.38    0       0       0       0       0       0       0       active+clean    2014-06-30 00:10:58.783103     0&#39;0     88:71   [2,0]   2       [2,0]   2       0&#39;0     2014-06-29 22:29:06.688363      0&#39;0   2014-06-26 19:52:08.827342&#10;1.3b    0       0       0       0       0       0       0       active+clean    2014-06-30 00:10:58.857283     0&#39;0     88:78   [1,0]   1       [1,0]   1       0&#39;0     2014-06-29 22:27:30.017050      0&#39;0   2014-06-26 19:52:08.644820&#10;0.3a    40      0       0       0       167772160       149     149     active+clean    2014-06-30 00:28:47.002342     52&#39;149  88:288  [0,2]   0       [0,2]   0       44&#39;46   2014-06-29 22:25:21.273679    0&#39;0      2014-06-26 19:52:08.508654&#10;3.39    0       0       0       0       0       0       0       active+clean    2014-06-30 00:16:13.255056     0&#39;0     88:21   [1,0]   1       [1,0]   1       0&#39;0     2014-06-30 00:15:05.447461      0&#39;0   2014-06-30 00:15:05.447461&#10;2.3b    0       0       0       0       0       0       0       active+clean    2014-06-30 00:10:48.935872     0&#39;0     88:57   [1,2]   1       [1,2]   1       0&#39;0     2014-06-29 22:28:35.095977      0&#39;0   2014-06-26 19:52:08.844571&#10;1.38    0       0       0       0       0       0       0       active+clean    2014-06-30 00:10:48.597540     0&#39;0     88:46   [2,1]   2       [2,1]   2       0&#39;0     2014-06-29 22:28:01.519137      0&#39;0   2014-06-26 19:52:08.633781&#10;0.39    48      0       0       0       201326592       164     164     active+clean    2014-06-30 00:25:30.757843     52&#39;164  88:432  [1,0]   1       [1,0]   1       44&#39;32   2014-06-29 22:26:33.823947    0&#39;0      2014-06-26 19:52:08.504628&#10;&#19979;&#38754;&#37096;&#20998;&#30465;&#30053;</span><br></pre></td></tr></table></figure>
<h2 id="2、查看一个PG的map">2、查看一个PG的map</h2><p>[root@client ~]# ceph pg map 0.3f<br>osdmap e88 pg 0.3f (0.3f) -&gt; up [0,2] acting [0,2]   #其中的[0,2]代表存储在osd.0、osd.2节点，osd.0代表主副本的存储位置</p>
<h2 id="3、查看PG状态">3、查看PG状态</h2><p>[root@client ~]# ceph pg stat<br>v1164: 448 pgs: 448 active+clean; 10003 MB data, 23617 MB used, 37792 MB / 61410 MB avail</p>
<h2 id="4、查询一个pg的详细信息">4、查询一个pg的详细信息</h2><p>[root@client ~]# ceph pg  0.26 query</p>
<h2 id="5、查看pg中stuck的状态">5、查看pg中stuck的状态</h2><p>[root@client ~]# ceph pg dump_stuck unclean<br>ok<br>[root@client ~]# ceph pg dump_stuck inactive<br>ok<br>[root@client ~]# ceph pg dump_stuck stale<br>ok</p>
<h2 id="6、显示一个集群中的所有的pg统计">6、显示一个集群中的所有的pg统计</h2><p>ceph pg dump —format plain</p>
<h2 id="7、恢复一个丢失的pg">7、恢复一个丢失的pg</h2><p>ceph pg {pg-id} mark_unfound_lost revert</p>
<h2 id="8、显示非正常状态的pg">8、显示非正常状态的pg</h2><p>ceph pg dump_stuck inactive|unclean|stale</p>
<h1 id="六、pool">六、pool</h1><h2 id="1、查看ceph集群中的pool数量">1、查看ceph集群中的pool数量</h2><p>[root@admin ~]# ceph osd lspools<br>0 data,1 metadata,2 rbd,</p>
<h2 id="2、在ceph集群中创建一个pool">2、在ceph集群中创建一个pool</h2><p>ceph osd pool create jiayuan 100            #这里的100指的是PG组</p>
<h2 id="3、为一个ceph_pool配置配额">3、为一个ceph pool配置配额</h2><p>ceph osd pool set-quota data max_objects 10000</p>
<h2 id="4、在集群中删除一个pool">4、在集群中删除一个pool</h2><p>ceph osd pool delete jiayuan  jiayuan  —yes-i-really-really-mean-it  #集群名字需要重复两次</p>
<h2 id="5、显示集群中pool的详细信息">5、显示集群中pool的详细信息</h2>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]# rados df&#10;pool name       category                 KB      objects       clones     degraded      unfound           rd        rd KB           wr        wr KB&#10;data            -                  475764704       116155            0            0           0            0            0       116379    475764704&#10;metadata        -                       5606           21            0            0           0            0            0          314         5833&#10;rbd             -                          0            0            0            0           0            0            0            0            0&#10;  total used       955852448       116176&#10;  total avail      639497596&#10;  total space     1595350044&#10;[root@admin ~]#</span><br></pre></td></tr></table></figure>
<h2 id="6、给一个pool创建一个快照">6、给一个pool创建一个快照</h2><p>[root@admin ~]# ceph osd pool mksnap data   date-snap<br>created pool data snap date-snap</p>
<h2 id="7、删除pool的快照">7、删除pool的快照</h2><p>[root@admin ~]# ceph osd pool rmsnap data date-snap<br>removed pool data snap date-snap</p>
<h2 id="8、查看data池的pg数量">8、查看data池的pg数量</h2><p>[root@admin ~]# ceph osd pool get data pg_num<br>pg_num: 64</p>
<h2 id="9、设置data池的最大存储空间为100T（默认是1T)">9、设置data池的最大存储空间为100T（默认是1T)</h2><p>[root@admin ~]# ceph osd pool set data target_max_bytes 100000000000000<br>set pool 0 target_max_bytes to 100000000000000</p>
<h2 id="10、设置data池的副本数是3">10、设置data池的副本数是3</h2><p>[root@admin ~]# ceph osd pool set data size 3<br>set pool 0 size to 3</p>
<h2 id="11、设置data池能接受写操作的最小副本为2">11、设置data池能接受写操作的最小副本为2</h2><p>[root@admin ~]# ceph osd pool set data min_size 2<br>set pool 0 min_size to 2</p>
<h2 id="12、查看集群中所有pool的副本尺寸">12、查看集群中所有pool的副本尺寸</h2>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@admin mycephfs]# ceph osd dump | grep &#39;replicated size&#39;&#10;pool 0 &#39;data&#39; replicated size 3 min_size 2 crush_ruleset 0 object_hash rjenkins pg_num 64 pgp_num 64 last_change 26 owner 0 flags hashpspool crash_replay_interval 45 target_bytes 100000000000000 stripe_width 0&#10;pool 1 &#39;metadata&#39; replicated size 2 min_size 1 crush_ruleset 0 object_hash rjenkins pg_num 64 pgp_num 64 last_change 1 owner 0 flags hashpspool stripe_width 0&#10;pool 2 &#39;rbd&#39; replicated size 2 min_size 1 crush_ruleset 0 object_hash rjenkins pg_num 64 pgp_num 64 last_change 1 owner 0 flags hashpspool stripe_width 0</span><br></pre></td></tr></table></figure>
<h2 id="13、设置一个pool的pg数量">13、设置一个pool的pg数量</h2><p>[root@admin ~]# ceph osd pool set data pg_num 100<br>set pool 0 pg_num to 100</p>
<h2 id="14、设置一个pool的pgp数量">14、设置一个pool的pgp数量</h2><p>[root@admin ~]# ceph osd pool set data pgp_num 100<br>set pool 0 pgp_num to 100</p>
<h1 id="七、rados和rbd指令">七、rados和rbd指令</h1><h2 id="1、rados命令使用方法">1、rados命令使用方法</h2><h3 id="（1）、查看ceph集群中pool数量">（1）、查看ceph集群中pool数量</h3><p> （只是查看pool)<br>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node-44 ~]# rados lspools&#10;data&#10;metadata&#10;rbd&#10;images&#10;volumes&#10;.rgw.root&#10;compute&#10;.rgw.control&#10;.rgw&#10;.rgw.gc&#10;.users.uid</span><br></pre></td></tr></table></figure></p>
<h3 id="（2）、查看ceph集群中pool容量及利用情况">（2）、查看ceph集群中pool容量及利用情况</h3>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node-44 ~]# rados df &#10;pool name       category                 KB      objects       clones     degraded      unfound           rd        rd KB           wr        wr KB&#10;.rgw            -                          0            0            0            0           0            0            0            0            0&#10;.rgw.control    -                          0            8            0            0           0            0            0            0            0&#10;.rgw.gc         -                          0           32            0            0           0        57172        57172        38136            0&#10;.rgw.root       -                          1            4            0            0           0           75           46           10           10&#10;.users.uid      -                          1            1            0            0           0            0            0            2            1&#10;compute         -                   67430708        16506            0            0           0       398128     75927848      1174683    222082706&#10;data            -                          0            0            0            0           0            0            0            0            0&#10;images          -                  250069744        30683            0            0           0        50881    195328724        65025    388375482&#10;metadata        -                          0            0            0            0           0            0            0            0            0&#10;rbd             -                          0            0            0            0           0            0            0            0            0&#10;volumes         -                   79123929        19707            0            0           0      2575693     63437000      1592456    163812172&#10;  total used       799318844        66941&#10;  total avail    11306053720&#10;  total space    12105372564&#10;[root@node-44 ~]#</span><br></pre></td></tr></table></figure>
<h3 id="（3）、创建一个pool">（3）、创建一个pool</h3><p>[root@node-44 ~]#rados mkpool test</p>
<h3 id="（4）、查看ceph_pool中的ceph_object">（4）、查看ceph pool中的ceph object</h3><p> （这里的object是以块形式存储的）<br>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node-44 ~]# rados ls -p volumes | more&#10;rbd_data.348f21ba7021.0000000000000866&#10;rbd_data.32562ae8944a.0000000000000c79&#10;rbd_data.589c2ae8944a.00000000000031ba&#10;rbd_data.58c9151ff76b.00000000000029af&#10;rbd_data.58c9151ff76b.0000000000002c19&#10;rbd_data.58c9151ff76b.0000000000000a5a&#10;rbd_data.58c9151ff76b.0000000000001c69&#10;rbd_data.58c9151ff76b.000000000000281d&#10;rbd_data.58c9151ff76b.0000000000002de1&#10;rbd_data.58c9151ff76b.0000000000002dae</span><br></pre></td></tr></table></figure></p>
<h3 id="（5）、创建一个对象object">（5）、创建一个对象object</h3><p>[root@admin-node ~]# rados create test-object -p test<br>[root@admin-node ~]# rados -p test ls<br>test-object</p>
<h3 id="（6）、删除一个对象">（6）、删除一个对象</h3><p>[root@admin-node ~]# rados rm test-object-1 -p test</p>
<h2 id="2、rbd命令的用法">2、rbd命令的用法</h2><h3 id="（1）、查看ceph中一个pool里的所有镜像">（1）、查看ceph中一个pool里的所有镜像</h3>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node-44 ~]# rbd ls images&#10;2014-05-24 17:17:37.043659 7f14caa6e700  0 -- :/1025604 &#62;&#62; 10.49.101.9:6789/0 pipe(0x6c5400 sd=3 :0 s=1 pgs=0 cs=0 l=1 c=0x6c5660).fault&#10;2182d9ac-52f4-4f5d-99a1-ab3ceacbf0b9&#10;34e1a475-5b11-410c-b4c4-69b5f780f03c&#10;476a9f3b-4608-4ffd-90ea-8750e804f46e&#10;60eae8bf-dd23-40c5-ba02-266d5b942767&#10;72e16e93-1fa5-4e11-8497-15bd904eeffe&#10;74cb427c-cee9-47d0-b467-af217a67e60a&#10;8f181a53-520b-4e22-af7c-de59e8ccca78&#10;9867a580-22fe-4ed0-a1a8-120b8e8d18f4&#10;ac6f4dae-4b81-476d-9e83-ad92ff25fb13&#10;d20206d7-ff31-4dce-b59a-a622b0ea3af6&#10;&#10;[root@node-44 ~]# rbd ls volumes&#10;2014-05-24 17:22:18.649929 7f9e98733700  0 -- :/1010725 &#62;&#62; 10.49.101.9:6789/0 pipe(0x96a400 sd=3 :0 s=1 pgs=0 cs=0 l=1 c=0x96a660).fault&#10;volume-0788fc6c-0dd4-4339-bad4-e9d78bd5365c&#10;volume-0898c5b4-4072-4cae-affc-ec59c2375c51&#10;volume-2a1fb287-5666-4095-8f0b-6481695824e2&#10;volume-35c6aad4-8ea4-4b8d-95c7-7c3a8e8758c5&#10;volume-814494cc-5ae6-4094-9d06-d844fdf485c4&#10;volume-8a6fb0db-35a9-4b3b-9ace-fb647c2918ea&#10;volume-8c108991-9b03-4308-b979-51378bba2ed1&#10;volume-8cf3d206-2cce-4579-91c5-77bcb4a8a3f8&#10;volume-91fc075c-8bd1-41dc-b5ef-844f23df177d&#10;volume-b1263d8b-0a12-4b51-84e5-74434c0e73aa&#10;volume-b84fad5d-16ee-4343-8630-88f265409feb&#10;volume-c03a2eb1-06a3-4d79-98e5-7c62210751c3&#10;volume-c17bf6c0-80ba-47d9-862d-1b9e9a48231e&#10;volume-c32bca55-7ec0-47ce-a87e-a883da4b4ccd&#10;volume-df8961ef-11d6-4dae-96ee-f2df8eb4a08c&#10;volume-f1c38695-81f8-44fd-9af0-458cddf103a3</span><br></pre></td></tr></table></figure>
<h3 id="（2）、查看ceph_pool中一个镜像的信息">（2）、查看ceph pool中一个镜像的信息</h3>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node-44 ~]# rbd info -p images --image 74cb427c-cee9-47d0-b467-af217a67e60a&#10;rbd image &#39;74cb427c-cee9-47d0-b467-af217a67e60a&#39;:&#10;        size 1048 MB in 131 objects&#10;        order 23 (8192 KB objects)&#10;        block_name_prefix: rbd_data.95c7783fc0d0&#10;        format: 2&#10;        features: layering</span><br></pre></td></tr></table></figure>
<h3 id="（3）、在test池中创建镜像">（3）、在test池中创建镜像</h3>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node-44 ~]# rbd create -p test --size 10000 zhanguo&#10;[root@node-44 ~]# rbd -p test info zhanguo    #&#26597;&#30475;&#26032;&#24314;&#30340;&#38236;&#20687;&#30340;&#20449;&#24687;&#10;rbd image &#39;zhanguo&#39;:&#10;        size 10000 MB in 2500 objects&#10;        order 22 (4096 KB objects)&#10;        block_name_prefix: rb.0.127d2.2ae8944a&#10;        format: 1&#10;[root@node-44 ~]#</span><br></pre></td></tr></table></figure>
<h3 id="（4）、删除一个镜像">（4）、删除一个镜像</h3><p>[root@node-44 ~]# rbd rm  -p test  lizhanguo<br>Removing image: 100% complete…done.</p>
<h3 id="（5）、调整一个镜像的尺寸">（5）、调整一个镜像的尺寸</h3>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node-44 ~]# rbd resize -p test --size 20000 zhanguo&#10;Resizing image: 100% complete...done.&#10;[root@node-44 ~]# rbd -p test info zhanguo   #&#35843;&#25972;&#21518;&#30340;&#38236;&#20687;&#22823;&#23567;&#10;rbd image &#39;zhanguo&#39;:&#10;        size 20000 MB in 5000 objects&#10;        order 22 (4096 KB objects)&#10;        block_name_prefix: rb.0.127d2.2ae8944a&#10;        format: 1&#10;[root@node-44 ~]#</span><br></pre></td></tr></table></figure>
<h3 id="（6）、给一个镜像创建一个快照">（6）、给一个镜像创建一个快照</h3>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node-44 ~]# rbd  snap create  test/zhanguo@zhanguo123  #&#27744;/&#38236;&#20687;@&#24555;&#29031;&#10;[root@node-44 ~]# rbd   snap ls  -p test zhanguo&#10;SNAPID NAME           SIZE &#10;     2 zhanguo123 20000 MB &#10;[root@node-44 ~]# &#10;[root@node-44 ~]# rbd info test/zhanguo@zhanguo123&#10;rbd image &#39;zhanguo&#39;:&#10;        size 20000 MB in 5000 objects&#10;        order 22 (4096 KB objects)&#10;        block_name_prefix: rb.0.127d2.2ae8944a&#10;        format: 1&#10;        protected: False&#10;[root@node-44 ~]#</span><br></pre></td></tr></table></figure>
<h3 id="（7）、查看一个镜像文件的快照">（7）、查看一个镜像文件的快照</h3><p>[root@os-node101 ~]# rbd snap ls  -p volumes volume-7687988d-16ef-4814-8a2c-3fbd85e928e4<br>SNAPID NAME                                               SIZE<br>     5 snapshot-ee7862aa-825e-4004-9587-879d60430a12 102400 MB </p>
<h3 id="（8）、删除一个镜像文件的一个快照快照">（8）、删除一个镜像文件的一个快照快照</h3><pre><code>快照所在的池/        快照所在的镜像文件           <span class="decorator">@ 快照</span>
</code></pre>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@os-node101 ~]# rbd snap rm volumes/volume-7687988d-16ef-4814-8a2c-3fbd85e928e4@snapshot-ee7862aa-825e-4004-9587-879d60430a12&#10;rbd: snapshot &#39;snapshot-60586eba-b0be-4885-81ab-010757e50efb&#39; is protected from removal.&#10;2014-08-18 19:23:42.099301 7fd0245ef760 -1 librbd: removing snapshot from header failed: (16) Device or resource busy&#10;&#19978;&#38754;&#19981;&#33021;&#21024;&#38500;&#26174;&#31034;&#30340;&#25253;&#38169;&#20449;&#24687;&#26159;&#27492;&#24555;&#29031;&#22791;&#20889;&#20445;&#25252;&#20102;&#65292;&#19979;&#38754;&#21629;&#20196;&#26159;&#21024;&#38500;&#20889;&#20445;&#25252;&#21518;&#20877;&#36827;&#34892;&#21024;&#38500;&#12290;&#10;[root@os-node101 ~]# rbd snap unprotect volumes/volume-7687988d-16ef-4814-8a2c-3fbd85e928e4@snapshot-ee7862aa-825e-4004-9587-879d60430a12&#10;[root@os-node101 ~]# rbd snap rm volumes/volume-7687988d-16ef-4814-8a2c-3fbd85e928e4@snapshot-ee7862aa-825e-4004-9587-879d60430a12</span><br></pre></td></tr></table></figure>
<h3 id="（9）删除一个镜像文件的所有快照">（9）删除一个镜像文件的所有快照</h3><p>[root@os-node101 ~]# rbd snap purge  -p volumes volume-7687988d-16ef-4814-8a2c-3fbd85e928e4<br>Removing all snapshots: 100% complete…done.</p>
<h3 id="（10）、把ceph_pool中的一个镜像导出">（10）、把ceph pool中的一个镜像导出</h3><p>导出镜像<br>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node-44 ~]# rbd export -p images --image 74cb427c-cee9-47d0-b467-af217a67e60a /root/aaa.img&#10;2014-05-24 17:16:15.197695 7ffb47a9a700  0 -- :/1020493 &#62;&#62; 10.49.101.9:6789/0 pipe(0x1368400 sd=3 :0 s=1 pgs=0 cs=0 l=1 c=0x1368660).fault&#10;Exporting image: 100% complete...done.</span><br></pre></td></tr></table></figure></p>
<p>导出云硬盘<br>   <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node-44 ~]# rbd export -p volumes --image volume-470fee37-b950-4eef-a595-d7def334a5d6 /var/lib/glance/ceph-pool/volumes/Message-JiaoBenJi-10.40.212.24&#10;2014-05-24 17:28:18.940402 7f14ad39f700  0 -- :/1032237 &#62;&#62; 10.49.101.9:6789/0 pipe(0x260a400 sd=3 :0 s=1 pgs=0 cs=0 l=1 c=0x260a660).fault&#10;Exporting image: 100% complete...done.</span><br></pre></td></tr></table></figure></p>
<h3 id="（11）、把一个镜像导入ceph中">（11）、把一个镜像导入ceph中</h3><p>（但是直接导入是不能用的，因为没有经过openstack,openstack是看不到的）<br>[root@node-44 ~]# rbd import /root/aaa.img -p images —image 74cb427c-cee9-47d0-b467-af217a67e60a<br>Importing image: 100% complete…done.</p>
]]></content>
    <summary type="html">
    <![CDATA[Ceph常用运维命令]]>
    
    </summary>
    
      <category term="ceph" scheme="http://www.anste.com/tags/ceph/"/>
    
      <category term="openstack" scheme="http://www.anste.com/tags/openstack/"/>
    
      <category term="openstack" scheme="http://www.anste.com/categories/openstack/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[virtualbox-bridge图文教程]]></title>
    <link href="http://www.anste.com/2015/06/15/virtualbox-bridge/"/>
    <id>http://www.anste.com/2015/06/15/virtualbox-bridge/</id>
    <published>2015-06-15T09:32:40.000Z</published>
    <updated>2015-06-15T09:35:36.134Z</updated>
    <content type="html"><![CDATA[<h1 id="Windows_7_virtualbox_bridge">Windows 7 virtualbox bridge</h1><p>安装virtualbox 和 extension插件后，进入系统控制面板-网络和共享中心<br><img src="http://7xjou5.com1.z0.glb.clouddn.com/virtualbox00.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/virtualbox01.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/virtualbox02.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/virtualbox03.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/virtualbox04.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/virtualbox05.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/virtualbox06.jpg" alt=""><br>选择virtualbox安装目录下的Oracle\VirtualBox\drivers\network\netflt\VBoxNetFltM.inf<br><img src="http://7xjou5.com1.z0.glb.clouddn.com/virtualbox07.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/virtualbox08.jpg" alt=""><br>弹出提示安装oracle驱动时选择允许即可。</p>
]]></content>
    <summary type="html">
    <![CDATA[virtualbox-bridge图文教程]]>
    
    </summary>
    
      <category term="virtualbox" scheme="http://www.anste.com/tags/virtualbox/"/>
    
      <category term="windows" scheme="http://www.anste.com/tags/windows/"/>
    
      <category term="windows" scheme="http://www.anste.com/categories/windows/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Juniper、cisco通过ip sla实现浮动路由自动切换]]></title>
    <link href="http://www.anste.com/2015/06/15/ip-sla/"/>
    <id>http://www.anste.com/2015/06/15/ip-sla/</id>
    <published>2015-06-15T01:43:21.000Z</published>
    <updated>2015-06-15T01:54:55.232Z</updated>
    <content type="html"><![CDATA[<p>参考： <a href="http://baike.baidu.com/view/7042261.htm" target="_blank" rel="external">http://baike.baidu.com/view/7042261.htm</a></p>
<h1 id="IP_SLA简介">IP SLA简介</h1><p>IP SLA是 Internet Protocol Service-Level Agreement的缩写，意思是互联网协议服务等级协议。<br>服务等级协议既可以用于关于网络服务供应商和客户间的一份合同，其中定义了服务类型、服务质量和客户付款等术语。又可以用于网络连通性测试的特殊场合，比如两台设备中间有交换设备、静态路由切换条件等。<br>本词条主要阐述关于网络连通性测试的应用。</p>
<h1 id="应用场合">应用场合</h1><p>IP SLA主要有以下三种应用场合：<br>1.浮动静态路由下一跳检测。<br>2.HSRP出接口检测。<br>3.PBR策略路由下一跳检测。</p>
<h1 id="配置实例">配置实例</h1><h2 id="Cisco_IP_SLA">Cisco IP SLA</h2>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">ip route <span class="number">2.2</span>.2.2 <span class="number">255.255</span>.255.255 <span class="number">10.1</span>.1.2  track <span class="number">10</span>  <span class="comment">#主浮动路由，调用IP SLA实现浮动路由自动切换</span></span><br><span class="line">ip route <span class="number">2.2</span>.2.2 <span class="number">255.255</span>.255.255 <span class="number">10.2</span>.2.2 <span class="number">254</span>  <span class="comment">#备用浮动路由</span></span><br><span class="line">!</span><br><span class="line">ip sla <span class="number">1</span>            <span class="comment">#IP SLA配置</span></span><br><span class="line"> icmp-echo <span class="number">2.2</span>.2.2 source-interface FastEthernet0/<span class="number">0</span></span><br><span class="line"> timeout <span class="number">3000</span></span><br><span class="line"> threshold <span class="number">2</span></span><br><span class="line"> frequency <span class="number">3</span></span><br><span class="line">ip sla schedule <span class="number">1</span> life forever start-time now</span><br><span class="line">!</span><br><span class="line">track <span class="number">10</span> rtr <span class="number">1</span> reachability</span><br><span class="line"> delay down <span class="number">10</span> up <span class="number">15</span></span><br><span class="line">!</span><br></pre></td></tr></table></figure>
<p>上述是cisco IP SLA配置实例，主要是：<br>第一步建立 IP SLA配置探测方式ICMP-ECHO，探测源端口FastEthernet0/0，过期时间timeout，阀值 2，重复频率 3；<br>第二步建立schedule， 声明探测周期，本实例是一直探测<br>第三步建立track，配置探测可达性参数 delay来避免频繁切换<br>第四步建立主备浮动路由，并且主路由调用track实现自动切换</p>
<h2 id="Juniper_IP_Monitoring">Juniper IP Monitoring</h2>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"> Example - IP Monitoring <span class="keyword">with</span> route fail-over configuration <span class="keyword">and</span> behavior</span><br><span class="line"></span><br><span class="line">SUMMARY:</span><br><span class="line">This article explains how to set up route fail-over by using IP Monitoring, <span class="keyword">and</span> explains fail-over behavior.</span><br><span class="line"></span><br><span class="line">PROBLEM OR GOAL:</span><br><span class="line">Basic configuration:</span><br><span class="line">The test window <span class="keyword">is</span> defined by specifying how many probes you are sending, how often, <span class="keyword">and</span> the time between test windows. In this example, three probes are sent <span class="number">15</span> seconds apart <span class="keyword">and</span> the test-interval indicates a <span class="number">10</span> second pause between test windows.</span><br><span class="line"></span><br><span class="line">	* set services rpm probe example test test-name probe-count <span class="number">3</span></span><br><span class="line">	* set services rpm probe example test test-name probe-interval <span class="number">15</span></span><br><span class="line">	* set services rpm probe example test test-name test-interval <span class="number">10</span></span><br><span class="line"></span><br><span class="line">The requirement <span class="keyword">for</span> fail-over <span class="keyword">is</span> provided by configuring the successive-loss <span class="keyword">and</span>/<span class="keyword">or</span> total-loss values. The conditions must be met inside of the test window; so this configuration will require that all three probes <span class="keyword">from</span> the test window be lost to cause a fail-over.</span><br><span class="line"></span><br><span class="line">	* set services rpm probe example test test-name thresholds successive-loss <span class="number">3</span></span><br><span class="line">	* set services rpm probe example test test-name thresholds total-loss <span class="number">3</span></span><br><span class="line"></span><br><span class="line">To complete the rpm setup, specify where the probes are being sent, <span class="keyword">and</span> which interface to use.  This example also includes the optional next-hop, though it <span class="keyword">is</span> <span class="keyword">not</span> required unless the probe needs to use a different next-hop than <span class="keyword">is</span> <span class="keyword">in</span> the routing table.</span><br><span class="line"></span><br><span class="line">	* set services rpm probe example test test-name target address <span class="number">10.0</span>.0.2</span><br><span class="line">	* set services rpm probe example test test-name destination-interface fe-<span class="number">0</span>/<span class="number">0</span>/<span class="number">0.0</span></span><br><span class="line">	* set services rpm probe example test test-name next-hop <span class="number">10.0</span>.0.2</span><br><span class="line"></span><br><span class="line">The final step <span class="keyword">is</span> to configure the policy to use the example configured above; upon failure, it will switch the next-hop of the static route configured to <span class="number">20.0</span>.0.2.</span><br><span class="line"></span><br><span class="line">	* set services ip-monitoring policy test match rpm-probe example</span><br><span class="line">	* set services ip-monitoring policy test then preferred-route route <span class="number">50.0</span>.0.0/<span class="number">8</span> next-hop <span class="number">20.0</span>.0.2</span><br></pre></td></tr></table></figure>
<p>上述是Juniper通过IP Monitoring实现类似cisco IP SLA的效果，需要设备支持IP Monitoring才行，具体命令以及说明参考以上命令。</p>
]]></content>
    <summary type="html">
    <![CDATA[Juniper、cisco通过ip sla实现浮动路由自动切换配置实例]]>
    
    </summary>
    
      <category term="cisco" scheme="http://www.anste.com/tags/cisco/"/>
    
      <category term="juniper" scheme="http://www.anste.com/tags/juniper/"/>
    
      <category term="network" scheme="http://www.anste.com/categories/network/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[通过fuel 6.0部署openstack juno版本图文教程]]></title>
    <link href="http://www.anste.com/2015/06/12/fuel-openstack/"/>
    <id>http://www.anste.com/2015/06/12/fuel-openstack/</id>
    <published>2015-06-12T06:46:10.000Z</published>
    <updated>2015-06-15T09:38:15.401Z</updated>
    <content type="html"><![CDATA[<h1 id="Openstack概述">Openstack概述</h1><p>Main services<br>•    Identity (Keystone)<br>•    Compute (Nova)<br>•    Image service (Glance)<br>•    Networking (Neutron)<br>•    Object Storage (Swift)<br>•    Block Storage (Cinder)<br>•    Orchestration (Heat)<br>•    Database Service (Trove)<br>•    Bare Metal (Ironic)<br>•    Data processing (Sahara)<br>•    Message service (Zaqar)<br>•    Key management (Barbican)<br>•    DNS (Designate)<br>•    Shared Filesystems (Manila)<br>•    Containers service (Magnum)<br>•    Application catalog (Murano)<br>•    Governance service (Congress)<br>•    Workflow service (Mistral)<br>•    Key-value store as a Service (MagnetoDB)<br>Supporting services<br>•    Dashboard (Horizon)<br>•    Telemetry (Ceilometer)<br>•    Common Libraries (Oslo)<br>•    Deployment (TripleO)<br>•    Command-line client (OpenStackClient)<br>•    Benchmark service (Rally)<br>•    Puppet modules (PuppetOpenStack)<br>以上为Openstack目前所有的核心项目，Openstack的优点是模块化，按需部署，根据自身需求选择不同的架构和模块，本openstack架构主要使用了Horizon、Keystone、Nova、Glance、Cinder这五个模块，服务器角色分为Controller、Compute、Storage三种，网络使用nova-network Vlan模式。<br>更多详情参考官方网站<a href="https://wiki.openstack.org/wiki/Main_Page" target="_blank" rel="external">https://wiki.openstack.org/wiki/Main_Page</a><br><strong>注意：本教程部署openstack juno 网络选择为nova-network vlan方式，存储使用cinder LVM over iscsi方式，原因是这种结构比较简单，维护成本比较低</strong></p>
<h1 id="Fuel部署Openstack">Fuel部署Openstack</h1><h2 id="实施环境">实施环境</h2><p>    Fuel Server<br>IP：10.20.0.2<br>CPU：单核<br>内存：2G<br>硬盘：30G以上<br>网卡：GBE Family Controller<br>操作系统：MirantisOpenStack-6.0.iso<br>Fuel官方网站：<a href="https://www.mirantis.com/" target="_blank" rel="external">https://www.mirantis.com/</a> （Openstack社区贡献排名前5）<br>    Openstack Server<br>IP：202.173.13.2-202.173.13.40<br>CPU：Intel(R) Xeon(R) CPU E5-2640 v2 @ 2.00GHz * 2<br>内存：128G<br>网卡：千兆电口网卡（本例采用3个网卡安装方式）<br>操作系统：CentOS release 6.5<br>内核版本：2.6.32-504.1.3.el6.x86_64</p>
<h2 id="Openstack部署">Openstack部署</h2><h3 id="Fuel_Server安装部署">Fuel Server安装部署</h3><p>下载安装镜像：<a href="https://www.mirantis.com/" target="_blank" rel="external">https://www.mirantis.com/</a><br>下载oracle virtualbox和extension插件：<a href="https://www.virtualbox.org/wiki/Downloads" target="_blank" rel="external">https://www.virtualbox.org/wiki/Downloads</a><br>注意：已经通过Fuel部署Openstack后要保存好fuel镜像，后续需要继续使用原镜像才可以进行扩容。<br>1)    安装virtualbox<br>2)    安装virtualbox插件<br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel01.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel02.jpg" alt=""><br>3)    安装Fuel<br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel03.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel04.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel05.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel06.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel07.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel08.jpg" alt=""><br>选择vdi文件存放路径，硬盘大小30G以上<br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel09.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel10.jpg" alt=""><br>备注：windows7 virtualbox 创建桥接网卡参考<a href="http://www.anste.com/2015/06/15/virtualbox-bridge/">http://www.anste.com/2015/06/15/virtualbox-bridge/</a><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel11.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel12.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel13.jpg" alt=""><br>Tab键可以修改IP地址范围和hostname等信息，开始安装操作系统<br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel14.jpg" alt=""><br>安装操作系统完毕后自动开始加压缩安装Fuel<br>安装完毕后登陆root 默认密码r00tme更改cobbler DNS（Fuel6.0 bug,不更改会导致无法通过web console管理虚拟机）<br>输入 dockerctl shell cobbler进入<br>然后 vi /etc/dnsmasq.upstream<br>  <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">domain test.com&#10;search test.com&#10;nameserver 127.0.0.1</span><br></pre></td></tr></table></figure></p>
<p>保存，重启dnsmasq<br>  <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/etc/init.d/dnsmasq restart</span><br></pre></td></tr></table></figure></p>
<p>将安装virtualbox虚拟机的电脑有线网卡IP地址更改为10.20.0.1 255.255.255.0</p>
<h3 id="openstack部署">openstack部署</h3><p>1)    Fuel端配置<br>访问<a href="http://10.20.0.2:8000/" target="_blank" rel="external">http://10.20.0.2:8000/</a>  用户名admin 密码admin<br>openstack 网络规划如下：<br>1.虚拟机私网 （Private or Fixed network ）192.168.253.0/24<br>2.管理网络（Management network） 192.168.254.0/24<br>3.存储网络（Storage network） 192.168.255.0/24<br>4.Fuel网络 （Administrative network ）10.20.0.0/24<br>5.公开网络（Public network） 202.173.13.2-202.173.13.40<br>6.浮动网络（Floating network） 202.173.13.41-202.173.13.254<br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel15.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel16.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel17.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel18.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel19.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel20.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel21.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel22.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel23.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel24.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel25.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel27.jpg" alt=""><br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel28.jpg" alt=""><br>保存相关配置，Fuel端配置完毕。<br>2)    Juniper交换机配置<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">set vlans vlan253 vlan-id <span class="number">253</span>   （虚拟机私网 <span class="number">192.168</span>.253.0/<span class="number">24</span>）</span><br><span class="line">set vlans vlan254 vlan-id <span class="number">254</span>   （openstack管理网络 <span class="number">192.168</span>.254.0/<span class="number">24</span>）</span><br><span class="line">set vlans vlan255 vlan-id <span class="number">255</span>   （openstack存储网络 <span class="number">192.168</span>.255.0/<span class="number">24</span>）</span><br><span class="line">set vlans vlan256 vlan-id <span class="number">256</span>   （Fuel网络 <span class="number">10.20</span>.0.0/<span class="number">24</span>）</span><br><span class="line">set vlans vlan11 vlan-id <span class="number">11</span>     （public网络、floating IP 网络 <span class="number">202.173</span>.13.0/<span class="number">24</span>）</span><br><span class="line">set interfaces ge-<span class="number">0</span>/<span class="number">0</span>/<span class="number">11</span> unit <span class="number">0</span> family ethernet-switching vlan members vlan256 （接入openstack服务器网卡<span class="number">1</span>，Fuel网络）</span><br><span class="line">set interfaces ge-<span class="number">0</span>/<span class="number">0</span>/<span class="number">12</span> unit <span class="number">0</span> family ethernet-switching port-mode trunk</span><br><span class="line">set interfaces ge-<span class="number">0</span>/<span class="number">0</span>/<span class="number">12</span> unit <span class="number">0</span> family ethernet-switching vlan members vlan11</span><br><span class="line">（接入openstack服务器网卡<span class="number">2</span>，public和floating网络）</span><br><span class="line">set interfaces ge-<span class="number">0</span>/<span class="number">0</span>/<span class="number">13</span> unit <span class="number">0</span> family ethernet-switching port-mode trunk</span><br><span class="line">set interfaces ge-<span class="number">0</span>/<span class="number">0</span>/<span class="number">13</span> unit <span class="number">0</span> family ethernet-switching vlan members vlan253</span><br><span class="line">set interfaces ge-<span class="number">0</span>/<span class="number">0</span>/<span class="number">13</span> unit <span class="number">0</span> family ethernet-switching vlan members vlan254</span><br><span class="line">set interfaces ge-<span class="number">0</span>/<span class="number">0</span>/<span class="number">13</span> unit <span class="number">0</span> family ethernet-switching vlan members vlan255</span><br><span class="line">set interfaces ge-<span class="number">0</span>/<span class="number">0</span>/<span class="number">13</span> unit <span class="number">0</span> family ethernet-switching native-vlan-id <span class="number">253</span></span><br><span class="line">（接入openstack服务器网卡<span class="number">3</span>，虚拟机私网、openstack管理和存储网络）</span><br></pre></td></tr></table></figure></p>
<p>注意：如果想让虚拟机私网可以在公司办公网访问，需要增加相关路由和策略，同时配置public、floating网络的网关<br>3)    Openstack服务器配置<br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel29.jpg" alt=""><br>服务器重启PXE引导后会自动进入bootstrap内存操作系统，等待系统加载完毕<br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel30.jpg" alt=""><br>等待5-10分钟后，在Fuel页面右上角可以看到未分配节点被发现<br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel31.jpg" alt=""><br>然后在Fuel节点页面进行增加节点<br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel32.jpg" alt=""><br>勾选未分配服务器后，再勾选需要分配的角色（Controller节点不能与其他角色分配到同一个服务器上，compute和storage角色可以共存在同一个服务器）<br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel33.jpg" alt=""><br>分配好角色后，返回节点页面，选择各个服务器的配置选项<br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel34.jpg" alt=""><br>进入服务器网络配置<br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel35.jpg" alt=""><br>拖动相关网络到对应网卡，应用配置，返回节点列表<br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel36.jpg" alt=""><br>分配完所有服务器角色和网络配置后，进入网络页面进行验证<br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel37.jpg" alt=""><br>验证通过后勾选所有已经分配好角色的服务器点击部署变更即可。<br>所有openstack服务器会自动重启后进入PXE安装，安装操作系统完毕后会自动通过puppet部署openstack相关组件。<br>注意：如果服务器重启后未正常进入PXE，请人工进入PXE即可。</p>
<h3 id="Openstack服务器配置">Openstack服务器配置</h3><p>安装完毕后，请root登陆openstack各个服务器（Controller，compute，Storage等）<br>vi /etc/ssh/sshd_config 开启密码登陆<br>  <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PasswordAuthentication yes&#10;/etc/init.d/sshd restart</span><br></pre></td></tr></table></figure></p>
<p>vi /etc/resolv.conf 配置DNS<br>  <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">domain test.com  # openstack &#22495;&#21517;&#65292;&#35831;&#33258;&#34892;&#26356;&#25913;&#10;search test.com  # openstack &#22495;&#21517;&#25628;&#32034;&#65292;&#35831;&#33258;&#34892;&#26356;&#25913;&#10;nameserver 202.173.10.87 #openstack DNS &#26381;&#21153;&#22120;&#22320;&#22336;&#65292;&#35831;&#33258;&#34892;&#26356;&#25913;&#10;nameserver 202.173.10.107 #openstack DNS&#26381;&#21153;&#22120;&#22320;&#22336;&#65292;&#35831;&#33258;&#34892;&#26356;&#25913;</span><br></pre></td></tr></table></figure></p>
<p>更改系统时区<br>  <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -f /etc/localtime&#10;ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br></pre></td></tr></table></figure></p>
<p>vi /etc/ntp.conf 配置NTP<br>  <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">server 202.173.101.43 burst iburst # openstack NTP server&#65292;&#35831;&#33258;&#34892;&#26356;&#25913;&#10;/etc/init.d/ntpd restart</span><br></pre></td></tr></table></figure></p>
<p>vi /etc/nova/nova.conf 配置默认filter（只需要配置Controller节点和compute节点）<br>  <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#37197;&#32622;scheduler_default_filters=AllHostsFilter&#65292;&#24182;&#27880;&#38144;&#20854;&#20182;&#10;scheduler_default_filters&#10;/etc/init.d/openstack-nova-scheduler  restart #&#25152;&#26377;Controller&#33410;&#28857;&#25191;&#34892;&#10;/etc/init.d/openstack-nova-compute  restart #&#25152;&#26377;compute&#33410;&#28857;&#25191;&#34892;</span><br></pre></td></tr></table></figure></p>
<h3 id="健康检查">健康检查</h3><p>部署完毕后，通过Fuel自带健康检查功能检测openstack系统各功能模块是否正常<br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel38.jpg" alt=""><br>正常情况下除了下图所示检测有异常，其他所有检测项应该全部通过<br><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel39.jpg" alt=""> </p>
<h3 id="后续扩容部署">后续扩容部署</h3><p><img src="http://7xjou5.com1.z0.glb.clouddn.com/fuel40.jpg" alt=""><br>部署完毕后，将Fuel虚拟机保存，把镜像文件保存好，后续每次扩容时将该虚拟机加载后，继续按照2.1,2.2进行操作扩容即可（每次都进入dockerctl shell cobbler查看下dnsmasq.upstream是否更改为127.0.0.1，否则无法通过openstack页面console管理虚拟机）。<br>注意：如果重新部署Fuel，原来的配置无法恢复，相当于重新部署新的openstack环境。</p>
]]></content>
    <summary type="html">
    <![CDATA[通过fuel 6.0部署openstack juno版本图文教程]]>
    
    </summary>
    
      <category term="fuel" scheme="http://www.anste.com/tags/fuel/"/>
    
      <category term="juno" scheme="http://www.anste.com/tags/juno/"/>
    
      <category term="openstack" scheme="http://www.anste.com/tags/openstack/"/>
    
      <category term="openstack" scheme="http://www.anste.com/categories/openstack/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[openstack常用镜像文件下载地址]]></title>
    <link href="http://www.anste.com/2015/06/12/openstack-mirrors/"/>
    <id>http://www.anste.com/2015/06/12/openstack-mirrors/</id>
    <published>2015-06-12T01:04:56.000Z</published>
    <updated>2015-06-12T04:59:23.281Z</updated>
    <content type="html"><![CDATA[<p>参考：<a href="https://www.rdoproject.org/Image_resources" target="_blank" rel="external">https://www.rdoproject.org/Image_resources</a><br>      <a href="http://thornelabs.net/2014/06/01/where-to-find-openstack-cloud-images.html" target="_blank" rel="external">http://thornelabs.net/2014/06/01/where-to-find-openstack-cloud-images.html</a></p>
<h1 id="Fedora">Fedora</h1><p>Fedora 22: <a href="https://getfedora.org/cloud/download/" target="_blank" rel="external">https://getfedora.org/cloud/download/</a><br>Fedora 20 32bit:<a href="http://cloud.fedoraproject.org/fedora-20.i386.qcow2" target="_blank" rel="external">http://cloud.fedoraproject.org/fedora-20.i386.qcow2</a><br>Fedora 20 64bit:<a href="http://cloud.fedoraproject.org/fedora-20.x86_64.qcow2" target="_blank" rel="external">http://cloud.fedoraproject.org/fedora-20.x86_64.qcow2</a><br>Fedora 19 32bit:<a href="http://cloud.fedoraproject.org/fedora-19.i386.qcow2" target="_blank" rel="external">http://cloud.fedoraproject.org/fedora-19.i386.qcow2</a><br>Fedora 19 64bit:<a href="http://cloud.fedoraproject.org/fedora-19.x86_64.qcow2" target="_blank" rel="external">http://cloud.fedoraproject.org/fedora-19.x86_64.qcow2</a></p>
<h1 id="CentOS">CentOS</h1><p>CentOS 7:<a href="http://cloud.centos.org/centos/7/images/" target="_blank" rel="external">http://cloud.centos.org/centos/7/images/</a><br>CentOS 6:<a href="http://cloud.centos.org/centos/6/images/" target="_blank" rel="external">http://cloud.centos.org/centos/6/images/</a></p>
<h1 id="Ubuntu">Ubuntu</h1><p>Ubuntu:<a href="https://cloud-images.ubuntu.com/" target="_blank" rel="external">https://cloud-images.ubuntu.com/</a></p>
<h1 id="RHEL">RHEL</h1><p>RHEL 7:<a href="https://access.redhat.com/downloads/content/69/ver=/rhel---7/7.0/x86_64/product-downloads" target="_blank" rel="external">https://access.redhat.com/downloads/content/69/ver=/rhel---7/7.0/x86_64/product-downloads</a><br>RHEL 6:<a href="https://rhn.redhat.com/rhn/software/channel/downloads/Download.do?cid=16952" target="_blank" rel="external">https://rhn.redhat.com/rhn/software/channel/downloads/Download.do?cid=16952</a></p>
<h1 id="Windows">Windows</h1><p>Windows Server 2012:<a href="http://www.cloudbase.it/ws2012/" target="_blank" rel="external">http://www.cloudbase.it/ws2012/</a><br>Windows 7镜像制作教程：<a href="http://cloud-ninja.org/2014/05/14/running-windows-7-guests-on-openstack-icehouse/" target="_blank" rel="external">http://cloud-ninja.org/2014/05/14/running-windows-7-guests-on-openstack-icehouse/</a></p>
<h1 id="CirrOS">CirrOS</h1><p>CirrOS:<a href="http://download.cirros-cloud.net/" target="_blank" rel="external">http://download.cirros-cloud.net/</a></p>
<h1 id="Debian">Debian</h1><p>Debian:<a href="http://thornelabs.net/2014/04/07/create-a-kvm-based-debian-7-openstack-cloud-image.html" target="_blank" rel="external">http://thornelabs.net/2014/04/07/create-a-kvm-based-debian-7-openstack-cloud-image.html</a></p>
<h1 id="SUSE">SUSE</h1><p>SUSE官方没有提供镜像下载，但是提供了镜像制作工具。下载地址：<a href="https://susestudio.com/" target="_blank" rel="external">https://susestudio.com/</a></p>
<h1 id="FreeBSD">FreeBSD</h1><p>FreeBSD官方没有提供镜像下载，制作工具下载地址：<a href="http://pellaeon.github.io/bsd-cloudinit/" target="_blank" rel="external">http://pellaeon.github.io/bsd-cloudinit/</a><br>FreeBSD 10.0镜像制作教程：<a href="https://raymii.org/s/tutorials/FreeBSD_10.0-release_Openstack_Image.html" target="_blank" rel="external">https://raymii.org/s/tutorials/FreeBSD_10.0-release_Openstack_Image.html</a><br>FreeBSD 9.X镜像制作教程：<a href="http://fosskb.wordpress.com/2013/07/24/bundling-freebsd-9-image-for-openstack/" target="_blank" rel="external">http://fosskb.wordpress.com/2013/07/24/bundling-freebsd-9-image-for-openstack/</a><br>FreeBSD镜像制作教程：<a href="http://cssoss.wordpress.com/2011/11/28/bundling-freebsd-image-for-openstack/" target="_blank" rel="external">http://cssoss.wordpress.com/2011/11/28/bundling-freebsd-image-for-openstack/</a></p>
]]></content>
    <summary type="html">
    <![CDATA[openstack常用镜像文件下载地址]]>
    
    </summary>
    
      <category term="openstack" scheme="http://www.anste.com/tags/openstack/"/>
    
      <category term="openstack" scheme="http://www.anste.com/categories/openstack/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[制作openstack ubuntu镜像文件]]></title>
    <link href="http://www.anste.com/2015/06/12/openstack-ubuntu/"/>
    <id>http://www.anste.com/2015/06/12/openstack-ubuntu/</id>
    <published>2015-06-12T00:52:45.000Z</published>
    <updated>2015-06-12T01:04:36.051Z</updated>
    <content type="html"><![CDATA[<p>openstack官方教程不对，暂时只修改ubuntu官方openstack镜像文件</p>
<h1 id="开启密码登陆">开启密码登陆</h1><p>创建instance时在【post-creation】中写入以下内容后即可，ssh用户名ubuntu 密码Test@test.cn</p>
<h1 id="!/bin/sh">!/bin/sh</h1><p>passwd ubuntu&lt;&lt;EOF<br>Test@test.cn<br>Test@test.cn<br>EOF<br>sed -i ‘s/PasswordAuthentication no/PasswordAuthentication yes/g’ /etc/ssh/sshd_config<br>service ssh restart</p>
<h1 id="修改官方镜像文件">修改官方镜像文件</h1><p>下载地址：<a href="https://cloud-images.ubuntu.com/trusty/current/" target="_blank" rel="external">https://cloud-images.ubuntu.com/trusty/current/</a><br>使用CentOS 6.6作为镜像制作系统，安装guestfish工具<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">guestfish --rw -a trusty-server-cloudimg-amd64-disk1.img</span><br><span class="line">&gt;&lt;fs&gt; run</span><br><span class="line">&gt;&lt;fs&gt; list-filesystems</span><br><span class="line">/dev/sda1: xfs</span><br><span class="line">&gt;&lt;fs&gt; mount /dev/sda1 /</span><br><span class="line">&gt;&lt;fs&gt; vi /etc/cloud/cloud.cfg</span><br><span class="line">disable_root:  false <span class="comment">#是否开启root用户登陆  true 关闭  false 开启</span></span><br><span class="line">ssh_pwauth:   true <span class="comment">#是否开启密码登陆  true 开启  false 关闭</span></span><br><span class="line"></span><br><span class="line">default_user:</span><br><span class="line">     name: ubuntu  <span class="comment">#默认创建用户名称</span></span><br><span class="line">     lock_passwd: <span class="keyword">False</span> <span class="comment">#是否锁定</span></span><br><span class="line">&gt;&lt;fs&gt; vi /etc/shadow</span><br><span class="line">粘贴加密后的密码到root：后（在CentOS6.6使用python -c <span class="string">'import crypt; print crypt.crypt("Test@test.cn", "$6$random_salt")'</span>加密后的密码 ）  <span class="comment">#配置root密码</span></span><br><span class="line">&gt;&lt;fs&gt; cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime   <span class="comment">#变更时区</span></span><br><span class="line">&gt;&lt;fs&gt; vi /etc/crontab  <span class="comment">#配置NTP</span></span><br><span class="line"><span class="number">0</span>  <span class="number">9</span>    * * *   root    /usr/sbin/ntpdate <span class="number">192.168</span>.253.4  <span class="comment">#自行替换成自己网络的NTP</span></span><br><span class="line">&gt;&lt;fs&gt; exit</span><br></pre></td></tr></table></figure></p>
<h1 id="上传镜像">上传镜像</h1>  <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp /home/trusty-server-cloudimg-amd64-disk1.img 192.168.13.5:/tmp  #192.168.13.5&#20026;openstack glance&#26381;&#21153;&#22120;&#65292;&#21363;openstack Controller&#10;&#30331;&#38470;192.168.13.5&#10;source /root/openrc&#10;glance image-create --name Ubuntu_amd64 --disk-format=qcow2 --container-format=bare --is-public=True --progress --file /tmp/trusty-server-cloudimg-amd64-disk1.img</span><br></pre></td></tr></table></figure>]]></content>
    <summary type="html">
    <![CDATA[定制化制作openstack ubuntu镜像文件]]>
    
    </summary>
    
      <category term="openstack" scheme="http://www.anste.com/tags/openstack/"/>
    
      <category term="ubuntu" scheme="http://www.anste.com/tags/ubuntu/"/>
    
      <category term="openstack" scheme="http://www.anste.com/categories/openstack/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[openstack windows2012镜像文件制作教程]]></title>
    <link href="http://www.anste.com/2015/06/11/openstack-Windows2012/"/>
    <id>http://www.anste.com/2015/06/11/openstack-Windows2012/</id>
    <published>2015-06-11T07:34:40.000Z</published>
    <updated>2015-06-11T08:08:27.034Z</updated>
    <content type="html"><![CDATA[<h1 id="Windows2012">Windows2012</h1><p>参考：<a href="http://docs.openstack.org/zh_CN/image-guide/content/windows-image.html" target="_blank" rel="external">http://docs.openstack.org/zh_CN/image-guide/content/windows-image.html</a></p>
<h2 id="安装windows2012">安装windows2012</h2><p>下载windows 2012镜像iso文件和virtio驱动文件到镜像制作主机192.168.9.100（CentOS6.6）<br>本文档版本：Windows2012_Standard_R2_x86_64.iso<br>本文档版本：virtio-win-drivers-20120712-1.iso<br>存放在/home目录下<br>在192.168.9.100上运行以下命令<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">virt-install --connect qemu:///system \</span><br><span class="line">  --name windows2012 --ram <span class="number">2048</span> --vcpus <span class="number">2</span> \</span><br><span class="line">  --network network=default,model=virtio \</span><br><span class="line">  --disk path=/home/windows2012.qcow2,format=qcow2,device=disk,bus=virtio \</span><br><span class="line">  --cdrom /home/Windows2012_Standard_R2_x86_64.iso \</span><br><span class="line">  --disk path=/home/virtio-win-drivers-<span class="number">20120712</span>-<span class="number">1.</span>iso,device=cdrom \</span><br><span class="line">  --vnc --os-type windows --os-variant win2k8</span><br></pre></td></tr></table></figure></p>
<p>进入virt-manager开始安装windows 2012<br>选择自定义 仅安装windows，会提示找不到硬盘，加载virtio驱动即可<br>硬盘驱动路径virtio-win-drivers-20120712-1.iso\STORAGE\SERVER_2008_R2\AMD64<br>网卡驱动路径virtio-win-drivers-20120712-1.iso\NETWORK\SERVER_2008_R2\AMD64<br>administrator 密码Test@test.cn<br>安装完毕后，以administrator用户登录如果提示网卡找不到，请重新安装网卡驱动</p>
<h2 id="安装cloudbaseinit程序">安装cloudbaseinit程序</h2><p>下载<a href="https://www.cloudbase.it/downloads/CloudbaseInitSetup_x64.msi" target="_blank" rel="external">https://www.cloudbase.it/downloads/CloudbaseInitSetup_x64.msi</a><br>在configuration options窗口，修改以下设置：（cloudbaseinit版本不同，选项略有不同，一般使用默认配置即可）<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">用户名： Administrator</span><br><span class="line"></span><br><span class="line">网卡：Red Hat VirtIO Ethernet Adapter</span><br><span class="line"></span><br><span class="line">日志输出串口：COM1</span><br><span class="line"></span><br><span class="line">当安装完成后，在Complete the Cloudbase-Init Setup Wizard 窗口，选择Run Sysprep和Shutdown 复选框，然后点击Finish。</span><br></pre></td></tr></table></figure></p>
<p>等待虚机关闭。</p>
<h2 id="压缩镜像：">压缩镜像：</h2><p>qemu-img convert -c /var/lib/libvirt/images/windows2012.qcow2 -O qcow2 /home/Windows2012STD_R2.qcow2<br>scp /home/Windows2012STD_R2.qcow2 192.168.13.5:/tmp   (192.168.13.5是openstack glance所在服务器)<br>登陆到192.168.13.5（openstack Controller节点），执行以下命令<br>source /root/openrc<br>glance image-create —name Windows2012STD_R2 —disk-format=qcow2 —container-format=bare —is-public=True —progress —file /tmp/ Windows2012STD_R2.qcow2<br>至此，windows2012镜像已经上传到openstack镜像源中。</p>
<h2 id="注意事项">注意事项</h2><p>1.新建instances成功后会提示配置管理员密码，此时可以随便设置自己的管理员密码<br>2.resize windows虚拟机会比较慢，耐心等待</p>
]]></content>
    <summary type="html">
    <![CDATA[制作openstack windows2012镜像文件教程]]>
    
    </summary>
    
      <category term="openstack" scheme="http://www.anste.com/tags/openstack/"/>
    
      <category term="windows" scheme="http://www.anste.com/tags/windows/"/>
    
      <category term="openstack" scheme="http://www.anste.com/categories/openstack/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[LVS、Haproxy、OSPF负载均衡技术对比]]></title>
    <link href="http://www.anste.com/2015/06/10/lvs/"/>
    <id>http://www.anste.com/2015/06/10/lvs/</id>
    <published>2015-06-10T06:48:44.408Z</published>
    <updated>2015-06-10T06:48:44.408Z</updated>
    <content type="html"><![CDATA[<h1 id="方案概述">方案概述</h1><h2 id="LVS">LVS</h2><p>LVS（Linux Virtual Server）使用集群技术和Linux操作系统实现一个高性能、高可用的服务器，它具有很好的可伸缩性。<br>特点：<br>1、抗负载能力强、是工作在网络4层之上仅作分发之用，没有流量的产生，这个特点也决定了它在负载均衡软件里的性能最强的；<br>2、配置性比较低，这是一个缺点也是一个优点，因为没有可太多配置的东西，所以并不需要太多接触，大大减少了人为出错的几率；<br>3、工作稳定，自身有完整的双机热备方案，如LVS+Keepalived和LVS+Heartbeat，不过我们在项目实施中用得最多的还是LVS/DR+Keepalived；<br>4、无流量，保证了均衡器IO的性能不会收到大流量的影响；<br>5、应用范围比较广，可以对所有应用做负载均衡；<br>6、软件本身不支持正则处理，不能做动静分离，这个就比较遗憾了；其实现在许多网站在这方面都有较强的需求，这个是Nginx/HAProxy+Keepalived的优势所在。<br>7、如果是网站应用比较庞大的话，实施LVS/DR+Keepalived起来就比较复杂了，特别后面有Windows Server应用的机器的话，如果实施及配置还有维护过程就比较复杂了，相对而言，Nginx/HAProxy+Keepalived就简单多了。</p>
<h2 id="HAProxy">HAProxy</h2><p>HAProxy提供高可用性、负载均衡以及基于TCP和HTTP应用的代 理，支持虚拟主机，它是免费、快速并且可靠的一种解决方案。HAProxy特别适用于那些负载特大的web站点，这些站点通常又需要会话保持或七层处理。HAProxy运行在当前的硬件上，完全可以支持数以万计的并发连接。并且它的运行模式使得它可以很简单安全的整合进您当前的架构中， 同时可以保护你的web服务器不被暴露到网络上。<br>特点：<br>1、HAProxy支持虚拟主机<br>2、能够补充Nginx的一些缺点比如Session的保持，Cookie的引导等工作<br>3、支持url检测后端的服务器出问题的检测会有很好的帮助。<br>4、它跟LVS一样，本身仅仅就只是一款负载均衡软件；单纯从效率上来讲HAProxy更会比Nginx有更出色的负载均衡速度，在并发处理上也是优于Nginx的。<br>5、HAProxy可以对Mysql读进行负载均衡，对后端的MySQL节点进行检测和负载均衡，不过在后端的MySQL slaves数量超过10台时性能不如LVS，所以我向大家推荐LVS+Keepalived。<br>6、HAProxy的算法现在也越来越多了，具体有如下8种：<br>①roundrobin，表示简单的轮询，这个不多说，这个是负载均衡基本都具备的；<br>②static-rr，表示根据权重，建议关注；<br>③leastconn，表示最少连接者先处理，建议关注；<br>④source，表示根据请求源IP，这个跟Nginx的IP_hash机制类似，我们用其作为解决session问题的一种方法，建议关注；<br>⑤ri，表示根据请求的URI；<br>⑥rl_param，表示根据请求的URl参数’balance url_param’ requires an URL parameter name；<br>⑦hdr(name)，表示根据HTTP请求头来锁定每一次HTTP请求；<br>⑧rdp-cookie(name)，表示根据据cookie(name)来锁定并哈希每一次TCP请求。</p>
<h2 id="Ospf（ECMP）">Ospf（ECMP）</h2><p>OSPF(Open Shortest Path First开放式最短路径优先）是一个内部网关协议(Interior Gateway Protocol，简称IGP），用于在单一自治系统（autonomous system,AS）内决策路由。<br>ECMP（Equal-CostMultipathRouting）等价多路径，存在多条不同链路到达同一目的地址的网络环境中，如果使用传统的路由技术，发往该目的地址的数据包只能利用其中的一条链路，其它链路处于备份状态或无效状态，并且在动态路由环境下相互的切换需要一定时间，而等值多路径路由协议可以在该网络环境下同时使用多条链路，不仅增加了传输带宽，并且可以无时延无丢包地备份失效链路的数据传输。<br>特点：<br>1.4层负载均衡，效率高<br>2.配置简单，只需安装基于linux的路由软件quagga<br>3.无法进行监控检查，服务异常无法处理<br>4.无session保持等，功能过于简单</p>
<h1 id="方案测试">方案测试</h1><h2 id="测试环境">测试环境</h2><p>LVS服务器<br>IP：192.168.0.9（主） 192.168.0.10（备）<br>CPU：Intel(R) Xeon(R) CPU           E5649  @ 2.53GHz<br>内存：32G<br>网卡：Broadcom NetXtreme II BCM5709 1000Base-T (C0) PCI Express<br>操作系统：CentOS release 5.8 (Final)<br>内核版本：2.6.18-308.8.2.el5<br>Web服务器<br>IP：192.168.0.14      192.168.0.15<br>CPU：Intel(R) Xeon(R) CPU           E5640  @ 2.67GHz<br>内存：32G<br>网卡：Broadcom NetXtreme II BCM5709 1000Base-T (C0) PCI Express<br>操作系统：CentOS release 6.3 (Final)<br>内核版本：2.6.32-220.17.1.el6.x86_64<br>Web服务：apache+php</p>
<h2 id="LVS测试">LVS测试</h2><h3 id="部署实施">部署实施</h3><p>安装<br>Ipvsadm版本：1.2.1<br>Keepalived版本：1.2.1<br>Root用户登录192.168.0.9/10系统依次执行以下命令安装：<br>yum -y install ipvsadm wget gcc gcc-c++ make openssl-devel kernel-devel<br>Wget <a href="http://keepalived.org/software/keepalived-1.2.1.tar.gz" target="_blank" rel="external">http://keepalived.org/software/keepalived-1.2.1.tar.gz</a><br>ln  -s  /usr/src/kernels/2.6.18-308.1.1.el5-x86_64/  /usr/src/linux<br>(将2.6.18-308.1.1.el5-x86_64替换为当前系统内核文件夹即可)<br>tar zxvf keepalived-1.2.3.tar.gz<br>cd keepalived-1.2.3<br>./configure<br>(注意这个步骤要看到以下字样才是正常的)<br>Use IPVS Framework : Yes<br>IPVS sync daemon support : Yes<br>make &amp;&amp; make install</p>
<h3 id="配置">配置</h3><p>cp /usr/local/etc/rc.d/init.d/keepalived /etc/rc.d/init.d/<br>cp /usr/local/etc/sysconfig/keepalived /etc/sysconfig/<br>mkdir /etc/keepalived<br>cp /usr/local/etc/keepalived/keepalived.conf /etc/keepalived/<br>cp /usr/local/sbin/keepalived /usr/sbin/<br>chkconfig —add keepalived<br>chkconfig —level 2345 keepalived on<br>配置keepalived文件<br>vi /etc/keepalived/keepalived.conf<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">! Configuration File <span class="keyword">for</span> keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">   notification_email &#123;</span><br><span class="line">     acassen<span class="decorator">@firewall.loc</span></span><br><span class="line">     failover<span class="decorator">@firewall.loc</span></span><br><span class="line">     sysadmin<span class="decorator">@firewall.loc   接收通知的邮箱</span></span><br><span class="line">   &#125;</span><br><span class="line">   notification_email_from Alexandre.Cassen<span class="decorator">@firewall.loc  通知发送邮箱</span></span><br><span class="line">   smtp_server mail01.knet.cn     邮箱服务器</span><br><span class="line">   smtp_connect_timeout <span class="number">30</span></span><br><span class="line">   router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER    keepalived状态参数，主为MASTER，备为SLAVE</span><br><span class="line">    interface eth1    keepalived信息发送接口</span><br><span class="line">    virtual_router_id <span class="number">51</span> 虚拟路由ID，同一组LVS需要配置为相同ID</span><br><span class="line">    priority <span class="number">100</span>   优先级，主&gt;备即可</span><br><span class="line">    advert_int <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass <span class="number">1111</span></span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        <span class="number">192.168</span>.0.23  虚拟服务IP</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_server <span class="number">192.168</span>.0.23 <span class="number">80</span> &#123; 虚拟服务IP 和端口</span><br><span class="line">    delay_loop <span class="number">6</span></span><br><span class="line">    lb_algo wrr   调度算法</span><br><span class="line">    lb_kind DR    工作模式</span><br><span class="line">    persistence_timeout <span class="number">60</span>  会话保持时间</span><br><span class="line">    protocol TCP</span><br><span class="line"></span><br><span class="line">    real_server <span class="number">192.168</span>.0.14 <span class="number">80</span> &#123;真实服务IP和端口</span><br><span class="line">        weight <span class="number">1</span></span><br><span class="line">        TCP_CHECK&#123;    健康检查</span><br><span class="line">            connect_timeout <span class="number">10</span></span><br><span class="line">            nb_get_retry <span class="number">3</span></span><br><span class="line">            delay_before_retry <span class="number">3</span></span><br><span class="line">            connect_port <span class="number">80</span></span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line">real_server <span class="number">192.168</span>.0.15 <span class="number">80</span> &#123;</span><br><span class="line">        weight <span class="number">1</span></span><br><span class="line">        TCP_CHECK&#123;</span><br><span class="line">            connect_timeout <span class="number">10</span></span><br><span class="line">            nb_get_retry <span class="number">3</span></span><br><span class="line">            delay_before_retry <span class="number">3</span></span><br><span class="line">            connect_port <span class="number">80</span></span><br><span class="line">        &#125;</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>备机keepalived文件与主大部分相同，只需要更改state和priority字段即可<br>配置Realserver 启动脚本<br>其中红色字段为iptables进行端口转换配置，需要根据相应服务真实端口进行变更。<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="comment"># description: Config realserver lo and apply noarp</span></span><br><span class="line">WEB_VIP=<span class="number">192.168</span>.0.23</span><br><span class="line"></span><br><span class="line">. /etc/rc.d/init.d/functions</span><br><span class="line"></span><br><span class="line">case <span class="string">"$1"</span> <span class="keyword">in</span></span><br><span class="line">start)</span><br><span class="line">        ifconfig lo:<span class="number">0</span> $WEB_VIP netmask <span class="number">255.255</span>.255.255 broadcast $WEB_VIP</span><br><span class="line">        /sbin/route add -host $WEB_VIP dev lo:<span class="number">0</span></span><br><span class="line">        echo <span class="string">"1"</span> &gt;/proc/sys/net/ipv4/conf/lo/arp_ignore</span><br><span class="line">        echo <span class="string">"2"</span> &gt;/proc/sys/net/ipv4/conf/lo/arp_announce</span><br><span class="line">        echo <span class="string">"1"</span> &gt;/proc/sys/net/ipv4/conf/all/arp_ignore</span><br><span class="line">        echo <span class="string">"2"</span> &gt;/proc/sys/net/ipv4/conf/all/arp_announce</span><br><span class="line">        sysctl -p &gt;/dev/null <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br><span class="line">        echo <span class="string">"RealServer Start OK"</span></span><br><span class="line"></span><br><span class="line">        ;;</span><br><span class="line">stop)</span><br><span class="line">        ifconfig lo:<span class="number">0</span> down</span><br><span class="line">        route <span class="keyword">del</span> $WEB_VIP &gt;/dev/null <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br><span class="line">        echo <span class="string">"0"</span> &gt;/proc/sys/net/ipv4/conf/lo/arp_ignore</span><br><span class="line">        echo <span class="string">"0"</span> &gt;/proc/sys/net/ipv4/conf/lo/arp_announce</span><br><span class="line">        echo <span class="string">"0"</span> &gt;/proc/sys/net/ipv4/conf/all/arp_ignore</span><br><span class="line">        echo <span class="string">"0"</span> &gt;/proc/sys/net/ipv4/conf/all/arp_announce</span><br><span class="line">        echo <span class="string">"RealServer Stoped"</span></span><br><span class="line">        ;;</span><br><span class="line">status)</span><br><span class="line">         <span class="comment"># Status of LVS-DR real server.</span></span><br><span class="line">         islothere=`/sbin/ifconfig lo:<span class="number">0</span> | grep $WEB_VIP`</span><br><span class="line">         isrothere=`netstat -rn | grep <span class="string">"lo:0"</span> | grep $web_VIP`</span><br><span class="line">         <span class="keyword">if</span> [ ! <span class="string">"$islothere"</span> -o ! <span class="string">"isrothere"</span> ];then</span><br><span class="line">             <span class="comment"># Either the route or the lo:0 device</span></span><br><span class="line">             <span class="comment"># not found.</span></span><br><span class="line">             echo <span class="string">"LVS-DR real server Stopped."</span></span><br><span class="line">         <span class="keyword">else</span></span><br><span class="line">             echo <span class="string">"LVS-DR Running."</span></span><br><span class="line">         fi</span><br><span class="line">;;</span><br><span class="line">*)</span><br><span class="line">         <span class="comment"># Invalid entry.</span></span><br><span class="line">         echo <span class="string">"$0: Usage: $0 &#123;start|status|stop&#125;"</span></span><br><span class="line">         exit <span class="number">1</span></span><br><span class="line">;;</span><br><span class="line">esac</span><br><span class="line">exit <span class="number">0</span></span><br></pre></td></tr></table></figure></p>
<h3 id="验证">验证</h3><p>访问真实服务地址<a href="http://192.168.0.14" target="_blank" rel="external">http://192.168.0.14</a> 应用正常<br>访问真实服务地址<a href="http://192.168.0.15" target="_blank" rel="external">http://192.168.0.15</a> 应用正常<br>访问虚拟服务地址<a href="http://192.168.0.23" target="_blank" rel="external">http://192.168.0.23</a> 应用正常<br>LVS实现负载均衡原理是通过修改mac字段将访问vip的数据包转发到相应realserver，转发要求RIP和DIP（LVS服务器IP）属于同一个网段才可以进行arp广播。所以现有四川三层架构无法支持LVS，需将LVS和RIP（真实服务器IP）修改为同一网段，变动较大，取消测试。</p>
<h3 id="功能测试">功能测试</h3><p>端口转发：DR模式+iptables<br>         LVS配置虚IP 192.168.0.23 端口80 对应真实服务IP 192.168.0.14/15 端口80<br>         真实服务器192.168.0.14/15 使用启动脚本<br>测试结果：正常转发请求<br>主备切换：主LVS停止keepalived服务，service keepalived stop，192.168.0.23端口80服务是否正常<br>测试结果：实时切换到备LVS提供负载均衡服务，服务正常，且用户不会觉察。</p>
<h3 id="性能测试">性能测试</h3><pre><code>压力测试工具：webbench、http_load
</code></pre><p>http_load<br>创建文件#vi urls<br>写入URL:<a href="http://192.168.0.23/index.html" target="_blank" rel="external">http://192.168.0.23/index.html</a><br>然后执行#./http_load -rate 5 -seconds 10 -parallel 500 urls<br>参数含义:<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">\-fetches 简写-f ：含义是总计的访问次数</span><br><span class="line">\-rate 简写-r ：含义是每秒的访问频率</span><br><span class="line">\-seconds简写-s ：含义是总计的访问时间</span><br><span class="line">\-parallel 简写-p：并发访问的线程数</span><br><span class="line">urls是一个url 列表，每个url 单独的一行。可以单个页面。</span><br></pre></td></tr></table></figure></p>
<p>返回结果<br>369097 fetches, 1000 max parallel, 2.88368e+09 bytes, in 60.0011 seconds<br>7812.81 mean bytes/connection<br>6151.5 fetches/sec, 4.80605e+07 bytes/sec<br>msecs/connect: 105.766 mean, 9036.84 max, 0.117 min<br>msecs/first-response: 35.2433 mean, 12993.4 max, 0.62 min<br>9 bad byte counts<br>HTTP response codes:<br>  code 200 — 369088</p>
<p>结果分析： 例如<br>219 fetches, 500 max parallel, 1.36262e+06 bytes, in 10.0008 seconds<br>219个请求，最大并发数500，总计传输的数据为1.36262e+06 bytes，运行时间10.0008秒<br>6222 mean bytes/connection<br>每一连接平均传输的数据量1.36262e+06/219=6222<br>21.8982 fetches/sec, 136251 bytes/sec<br>每秒的响应请求为21.8982，每秒传递的数据为136251btyes/sec<br>msecs/connect: 411.015 mean, 9080.76 max, 69.914 min<br>没连接的平均响应时间是411.015 means，最大响应时间9080.76 msecs，最小响应时间69.914 msecs<br>msecs/first-response: 148.292 mean, 3686.02 max, 70.624 min<br>HTTP response codes:<br>code 200 — 219</p>
<p>Webbench<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">参数说明：-c表示并发数，-t表示持续时间(秒)</span><br><span class="line">Webbench –c <span class="number">1000</span> –t <span class="number">60</span> http://<span class="number">192.168</span>.0.23/index.html</span><br><span class="line">Webbench - Simple Web Benchmark <span class="number">1.5</span></span><br><span class="line">Copyright (c) Radim Kolar <span class="number">1997</span>-<span class="number">2004</span>, GPL Open Source Software.</span><br><span class="line"></span><br><span class="line">Benchmarking: GET http://<span class="number">192.168</span>.0.23/index.html</span><br><span class="line"><span class="number">1000</span> clients, running <span class="number">60</span> sec.</span><br><span class="line"></span><br><span class="line">Speed=<span class="number">398317</span> pages/min, -<span class="number">17916648</span> bytes/sec.</span><br><span class="line">Requests: <span class="number">398284</span> susceed, <span class="number">33</span> failed.</span><br></pre></td></tr></table></figure></p>
<h2 id="HAProxy测试">HAProxy测试</h2><h3 id="部署实施-1">部署实施</h3><p>安装<br>使用root用户登录192.168.0.9<br>依次运行以下命令：<br>Wget <a href="http://haproxy.1wt.eu/download/1.4/src/haproxy-1.4.21.tar.gz" target="_blank" rel="external">http://haproxy.1wt.eu/download/1.4/src/haproxy-1.4.21.tar.gz</a><br>在haprxoy安装包目录下生成安装脚本haproxy_install.sh<br>  <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">#install haproxy </span><br><span class="line">#20111207 by dongnan</span><br><span class="line"></span><br><span class="line">#variables</span><br><span class="line">dir=/usr/local</span><br><span class="line">ha_dir=$&#123;dir&#125;/haproxy</span><br><span class="line">ha_cfg=$&#123;ha_dir&#125;/haproxy.cfg</span><br><span class="line">kernel=`uname -r | grep '2.6'`</span><br><span class="line">pcre=$(rpm -qa | grep 'pcre' | wc -l)</span><br><span class="line">echo "$dir, $ha_dir, $ha_cfg, $kernel, $pcre"</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#check</span><br><span class="line">if [ ! "$kernel" -o "$pcre" -lt "2" ];then</span><br><span class="line">    echo -e "the script need linux 2.6 kernel and pcre pcre-devel \nyou can usage 'yum install pcre pcre-devel' or 'rpm -ivh pcre-devel-6.6-2.el5_1.7.x86_64.rpm'"</span><br><span class="line">    exit 1</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">#function</span><br><span class="line"></span><br><span class="line">install_ha_cfg ()&#123;</span><br><span class="line">#configure haproxy.cfg</span><br><span class="line">#default configure file for test,but need your change the frontend server and backend server ip address,</span><br><span class="line">#good luck!</span><br><span class="line"></span><br><span class="line">echo '</span><br><span class="line">global</span><br><span class="line">    log 127.0.0.1   local0</span><br><span class="line">    maxconn 40960              #单个进程最大连接数</span><br><span class="line">    chroot /usr/local/haproxy #安装目录</span><br><span class="line">    uid 99                    #用户haproxy</span><br><span class="line">    gid 99                    #组haproxy</span><br><span class="line">    daemon                    #守护进程运行</span><br><span class="line">    nbproc 1                  #进程数量</span><br><span class="line">    pidfile /usr/local/haproxy/logs/haproxy.pid #haproxy pid</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line">   log     global</span><br><span class="line">   mode    http               #7层 http;4层tcp</span><br><span class="line">   option  httplog            #http 日志格式</span><br><span class="line">   option  httpclose          #主动关闭http通道</span><br><span class="line">   option  redispatch         #serverId对应的服务器挂掉后,强制定向到其他健康的服务器</span><br><span class="line">   option log-health-checks   #记录健康检查日志</span><br><span class="line">   option  dontlognull        #不记录空连接</span><br><span class="line">   maxconn 30000               #最大连接数</span><br><span class="line">   contimeout      5000       #连接超时(毫秒)</span><br><span class="line">   clitimeout      50000      #客户端超时(毫秒)</span><br><span class="line">   srvtimeout      50000      #服务器超时(毫秒)</span><br><span class="line"></span><br><span class="line">frontend haproxy_kx         #定义前端服务器(haproxy)</span><br><span class="line">        bind 0.0.0.0:80    #监听地址</span><br><span class="line">        default_backend server_pool  #指定后端服务器群</span><br><span class="line">        #errorfile 502 /usr/local/haproxy/html/maintain.html</span><br><span class="line">        #errorfile 503 /usr/local/haproxy/html/maintain.html</span><br><span class="line">        #errorfile 504 /usr/local/haproxy/html/maintain.html</span><br><span class="line"></span><br><span class="line">backend server_pool           #定义后端服务器群(web server/apache/nginx/iis..)</span><br><span class="line">        mode http</span><br><span class="line">        option  forwardfor    #后端服务器(apache/nginx/iis/*),从Http Header中获得客户端IP</span><br><span class="line">        #balance roundrobin    #负载均衡的方式,轮询方式</span><br><span class="line">        balance leastconn     #负载均衡的方式,最小连接</span><br><span class="line">        cookie SERVERID insert nocache       #插入serverid到cookie中,serverid后面可以定义</span><br><span class="line">        #option  httpchk HEAD /check.html #用来做健康检查html文档</span><br><span class="line">        server server1 192.168.0.14:80 cookie server1 check inter 2000 rise 3 fall 3 weight 3</span><br><span class="line">        server server2 192.168.0.15:80 cookie server2 check inter 2000 rise 3 fall 3 weight 3</span><br><span class="line">#服务器定义:</span><br><span class="line">#cookie server1表示serverid为server1;</span><br><span class="line">#check inter 2000 是检测心跳频率(check 默认 );</span><br><span class="line">#rise 3 表示 3次正确认为服务器可用;</span><br><span class="line">#fall 3 表示 3次失败认为服务器不可用;</span><br><span class="line">#weight 表示权重。</span><br><span class="line"></span><br><span class="line">listen admin_stat                   #status</span><br><span class="line">    bind *:8080                     #监听端口</span><br><span class="line">    mode http                       #http的7层模式</span><br><span class="line">    stats refresh 30s               #统计页面自动刷新时间</span><br><span class="line">    stats uri /haproxy-stats        #统计页面URL</span><br><span class="line">    stats realm Haproxy\ Statistics #统计页面密码框上提示文本</span><br><span class="line">    stats auth admin:admin          #统计页面用户名和密码设置</span><br><span class="line">    stats hide-version              #隐藏统计页面上HAProxy的版本信息</span><br><span class="line">    stats admin if TRUE             #手工启用/禁用,后端服务器' &gt; "$ha_cfg" &amp;&amp; sed -i '1 d' "$ha_cfg"</span><br><span class="line">&#125;</span><br><span class="line">   </span><br><span class="line"></span><br><span class="line">#install</span><br><span class="line">if [ ! -e "$ha_dir" ];then</span><br><span class="line">   tar zxf haproxy*.tar.gz</span><br><span class="line">   cd haproxy*/</span><br><span class="line">   make TARGET=linux26 USE_STATIC_PCRE=1 PREFIX=/usr/local/haproxy &amp;&amp; make install PREFIX=/usr/local/haproxy &amp;&amp; mkdir /usr/local/haproxy/&#123;html,logs&#125;</span><br><span class="line">   cd ../</span><br><span class="line">#</span><br><span class="line">   if [ ! -e "$ha_dir" ];then</span><br><span class="line">       echo "error! can't install haproxy  please check ! Will now out of the script !"</span><br><span class="line">       exit 1</span><br><span class="line">   else</span><br><span class="line">       ! grep 'haproxy' /etc/syslog.conf &amp;&amp; echo 'local1.*            /var/log/haproxy.log' &gt;&gt; /etc/syslog.conf</span><br><span class="line">       sed -ir 's/SYSLOGD_OPTIONS="-m 0"/SYSLOGD_OPTIONS="-r -m 0"/g' /etc/sysconfig/syslog &amp;&amp; /etc/init.d/syslog restart</span><br><span class="line">       install_ha_cfg</span><br><span class="line">       rm -rf haproxy*/</span><br><span class="line">   fi</span><br><span class="line">else</span><br><span class="line">   echo "haproxy is already exists!"</span><br><span class="line">fi</span><br></pre></td></tr></table></figure></p>
<p>运行脚本安装<br>sh haproxy_install.sh(注意脚本要和安装包在同一个目录下)<br>主备双机热备部署<br>Root用户执行：<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">yum -y install heartbeat</span><br><span class="line">yum -y install heartbeat</span><br><span class="line">cp /usr/share/doc/heartbeat-<span class="number">2.1</span>.3/ha.cf /etc/ha.d/ <span class="comment">#heartbeat主配置文件</span></span><br><span class="line">cp /usr/share/doc/heartbeat-<span class="number">2.1</span>.3/authkeys /etc/ha.d/ <span class="comment">#权限验证文件</span></span><br><span class="line">cp /usr/share/doc/heartbeat-<span class="number">2.1</span>.3/haresources /etc/ha.d/ <span class="comment">#资源配置文件，设置共享IP</span></span><br><span class="line">cd /etc/ha.d</span><br></pre></td></tr></table></figure></p>
<p>vi authkeys<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">auth <span class="number">1</span></span><br><span class="line"><span class="number">1</span> crc</span><br></pre></td></tr></table></figure></p>
<p>vi ha.cf<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">logfile /var/log/ha-log</span><br><span class="line">logfacility local0</span><br><span class="line">keepalive <span class="number">2</span></span><br><span class="line">deadtime <span class="number">10</span></span><br><span class="line">warntime <span class="number">5</span></span><br><span class="line">initdead <span class="number">120</span></span><br><span class="line">udpport <span class="number">694</span></span><br><span class="line">ucast eth0 <span class="number">192.168</span>.0.9 <span class="comment"># 注意，此处各服务器上的配置不同，此参数应设置为另一台服务器的IP地址</span></span><br><span class="line">auto_failback on</span><br><span class="line">node HA01</span><br><span class="line">node HA02</span><br></pre></td></tr></table></figure></p>
<p>vi haresources<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">HA01 IPaddr::<span class="number">192.168</span>.0.24/<span class="number">32</span>/eth0（HA01为主节点主机名，<span class="number">192.168</span>.0.24为服务虚地址，<span class="number">32</span>为掩码，eth0为接口）</span><br><span class="line">chkconfig heartbeat on</span><br><span class="line">service heartbeat start(注意先起主服务器heartbeat，等主服务虚地址启用后再起备服务器的heartbeat)</span><br><span class="line">service heartbeat start</span><br></pre></td></tr></table></figure></p>
<h3 id="配置-1">配置</h3><p>生成haproxy启动脚本haproxy.sh<br>内容如下：</p>
<h1 id="cat_/usr/local/sbin/haproxy-sh">cat /usr/local/sbin/haproxy.sh</h1>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="comment">#haproxy command </span></span><br><span class="line"><span class="comment">#ver:0.1bate</span></span><br><span class="line"><span class="comment">#20111129 by dongnan</span></span><br><span class="line"><span class="comment">#/usr/local/haproxy/sbin/haproxy </span></span><br><span class="line"><span class="comment">#HA-Proxy version 1.4.18 2011/09/16</span></span><br><span class="line"><span class="comment">#Copyright 2000-2011 Willy Tarreau &lt;w@1wt.eu&gt;</span></span><br><span class="line">         <span class="comment">#</span></span><br><span class="line">         <span class="comment">#Usage : haproxy [-f &lt;cfgfile&gt;]* [ -vdVD ] [ -n &lt;maxconn&gt; ] [ -N &lt;maxpconn&gt; ]</span></span><br><span class="line">         <span class="comment">#        [ -p &lt;pidfile&gt; ] [ -m &lt;max megs&gt; ]</span></span><br><span class="line">         <span class="comment">#        -v displays version ; -vv shows known build options.</span></span><br><span class="line">         <span class="comment">#        -d enters debug mode ; -db only disables background mode.</span></span><br><span class="line">         <span class="comment">#        -V enters verbose mode (disables quiet mode)</span></span><br><span class="line">         <span class="comment">#        -D goes daemon</span></span><br><span class="line">         <span class="comment">#        -q quiet mode : don't display messages</span></span><br><span class="line">         <span class="comment">#        -c check mode : only check config files and exit</span></span><br><span class="line">         <span class="comment">#        -n sets the maximum total # of connections (2000)</span></span><br><span class="line">         <span class="comment">#        -m limits the usable amount of memory (in MB)</span></span><br><span class="line">         <span class="comment">#        -N sets the default, per-proxy maximum # of connections (2000)</span></span><br><span class="line">         <span class="comment">#        -p writes pids of all children to this file</span></span><br><span class="line">         <span class="comment">#        -de disables epoll() usage even when available</span></span><br><span class="line">         <span class="comment">#        -ds disables speculative epoll() usage even when available</span></span><br><span class="line">         <span class="comment">#        -dp disables poll() usage even when available</span></span><br><span class="line">         <span class="comment">#        -sf/-st [pid ]* finishes/terminates old pids. Must be last arguments.</span></span><br><span class="line">         </span><br><span class="line">         <span class="comment">#variables</span></span><br><span class="line">         haproxy_dir=/usr/local/haproxy/</span><br><span class="line">         haproxy_conf=$&#123;haproxy_dir&#125;haproxy.cfg</span><br><span class="line">         haproxy_pid=$&#123;haproxy_dir&#125;logs/haproxy.pid</span><br><span class="line">         haproxy_cmd=$&#123;haproxy_dir&#125;sbin/haproxy</span><br><span class="line">         <span class="comment">#test variables</span></span><br><span class="line">         <span class="comment">#file $haproxy_dir; file $haproxy_conf; file $haproxy_cmd; file $haproxy_pid</span></span><br><span class="line">         </span><br><span class="line">         </span><br><span class="line">         </span><br><span class="line">         <span class="keyword">if</span> [ <span class="string">"$#"</span> -eq <span class="string">"0"</span> ];then</span><br><span class="line">             echo <span class="string">"usage: $0 &#123;start|stop|restart&#125;"</span></span><br><span class="line">             exit <span class="number">1</span></span><br><span class="line">         fi</span><br><span class="line">         </span><br><span class="line">         <span class="keyword">if</span> [ <span class="string">"$1"</span> = <span class="string">"start"</span> ];then</span><br><span class="line">         <span class="comment">#echo $1</span></span><br><span class="line">             $haproxy_cmd -f $haproxy_conf</span><br><span class="line">         <span class="keyword">elif</span> [ <span class="string">"$1"</span> = <span class="string">"stop"</span> ];then</span><br><span class="line">         <span class="comment">#echo $1</span></span><br><span class="line">             kill `cat $haproxy_pid`</span><br><span class="line">         <span class="keyword">elif</span> [ <span class="string">"$1"</span> = <span class="string">"restart"</span> ];then</span><br><span class="line">         <span class="comment">#echo $1</span></span><br><span class="line">             $haproxy_cmd -f $haproxy_conf -st `cat $haproxy_pid`</span><br><span class="line">         </span><br><span class="line">         <span class="keyword">else</span></span><br><span class="line">            echo <span class="string">"usage: $0 arguments only start and stop or restart !"</span></span><br><span class="line">     fi</span><br></pre></td></tr></table></figure>
<p>更改文件<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Chmod <span class="number">777</span> haproxy_install.sh haproxy.sh</span><br></pre></td></tr></table></figure></p>
<p>在haproxy安装包目录下执行安装脚本，安装完毕，更改haproxy.cfg配置文件<br>     ./haproxy_install.sh<br>     vi /usr/local/haproxy/haproxy.cfg<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">global</span></span><br><span class="line">    log <span class="number">127.0</span>.0.1   local0</span><br><span class="line">    maxconn <span class="number">40960</span>              <span class="comment">#最大连接数</span></span><br><span class="line">    chroot /usr/local/haproxy <span class="comment">#安装目录</span></span><br><span class="line">    uid <span class="number">99</span>                    <span class="comment">#用户haproxy</span></span><br><span class="line">    gid <span class="number">99</span>                    <span class="comment">#组haproxy</span></span><br><span class="line">    daemon                    <span class="comment">#守护进程运行</span></span><br><span class="line">    nbproc <span class="number">1</span>                  <span class="comment">#进程数量</span></span><br><span class="line">    pidfile /usr/local/haproxy/logs/haproxy.pid <span class="comment">#haproxy pid</span></span><br><span class="line">    </span><br><span class="line">defaults</span><br><span class="line">   log     <span class="keyword">global</span></span><br><span class="line">   mode    http               <span class="comment">#7层 http;4层tcp </span></span><br><span class="line">   option  httplog            <span class="comment">#http 日志格式</span></span><br><span class="line">   option  httpclose          <span class="comment">#主动关闭http通道</span></span><br><span class="line">   option  redispatch         <span class="comment">#serverId对应的服务器挂掉后,强制定向到其他健康的服务器</span></span><br><span class="line">    </span><br><span class="line">   option  dontlognull</span><br><span class="line">   maxconn <span class="number">30000</span>               <span class="comment">#最大连接数</span></span><br><span class="line">   contimeout      <span class="number">5000</span>       <span class="comment">#连接超时(毫秒)</span></span><br><span class="line">   clitimeout      <span class="number">50000</span>      <span class="comment">#客户端超时(毫秒)</span></span><br><span class="line">   srvtimeout      <span class="number">50000</span>      <span class="comment">#服务器超时(毫秒)</span></span><br><span class="line"> </span><br><span class="line">frontend haproxy_kx         <span class="comment">#定义前端服务器(haproxy)</span></span><br><span class="line">        bind <span class="number">192.168</span>.0.9:<span class="number">80</span>    <span class="comment">#监听地址</span></span><br><span class="line">        default_backend server_pool  <span class="comment">#指定后端服务器群</span></span><br><span class="line">        <span class="comment">#errorfile 502 /usr/local/haproxy/html/maintain.html</span></span><br><span class="line">        <span class="comment">#errorfile 503 /usr/local/haproxy/html/maintain.html</span></span><br><span class="line">        <span class="comment">#errorfile 504 /usr/local/haproxy/html/maintain.html</span></span><br><span class="line"> </span><br><span class="line">backend server_pool           <span class="comment">#定义后端服务器群(web server/apache/nginx/iis..)</span></span><br><span class="line">        mode http</span><br><span class="line">        option  forwardfor    <span class="comment">#后端服务器(apache/nginx/iis/*),从Http Header中获得客户端IP</span></span><br><span class="line">        <span class="comment">#balance roundrobin    #负载均衡的方式,轮询方式</span></span><br><span class="line">        balance leastconn     <span class="comment">#负载均衡的方式,最小连接</span></span><br><span class="line">        cookie SERVERID       <span class="comment">#插入serverid到cookie中,serverid后面可以定义</span></span><br><span class="line">        <span class="comment">#option  httpchk HEAD /check.html #用来做健康检查html文档</span></span><br><span class="line">        server server1 <span class="number">192.168</span>.0.14:<span class="number">80</span> cookie server1 check inter <span class="number">2000</span> rise <span class="number">3</span> fall <span class="number">3</span> weight <span class="number">3</span></span><br><span class="line">        server server2 <span class="number">192.168</span>.0.15:<span class="number">80</span> cookie server2 check inter <span class="number">2000</span> rise <span class="number">3</span> fall <span class="number">3</span> weight <span class="number">3</span></span><br><span class="line">        <span class="comment">#server server3 10.0.1.254:80 cookie server3 check maxconn 90 rise 2 fall 3 weight 3</span></span><br><span class="line"><span class="comment">#服务器定义:</span></span><br><span class="line"><span class="comment">#cookie server1表示serverid为server1;</span></span><br><span class="line"><span class="comment">#check inter 2000 是检测心跳频率(check 默认 );</span></span><br><span class="line"><span class="comment">#rise 3 表示 3次正确认为服务器可用;</span></span><br><span class="line"><span class="comment">#fall 3 表示 3次失败认为服务器不可用;</span></span><br><span class="line"><span class="comment">#weight 表示权重。</span></span><br><span class="line">    </span><br><span class="line">listen admin_stat                   <span class="comment">#status</span></span><br><span class="line">    bind *:<span class="number">8080</span>                     <span class="comment">#监听端口</span></span><br><span class="line">    mode http                       <span class="comment">#http的7层模式</span></span><br><span class="line">    stats refresh <span class="number">30</span>s               <span class="comment">#统计页面自动刷新时间</span></span><br><span class="line">    stats uri /haproxy-stats        <span class="comment">#统计页面URL</span></span><br><span class="line">    stats realm Haproxy\ Statistics <span class="comment">#统计页面密码框上提示文本</span></span><br><span class="line">    stats auth admin:admin          <span class="comment">#统计页面用户名和密码设置</span></span><br><span class="line">    stats hide-version              <span class="comment">#隐藏统计页面上HAProxy的版本信息</span></span><br><span class="line">    stats admin <span class="keyword">if</span> TRUE             <span class="comment">#手工启用/禁用,后端服务器</span></span><br></pre></td></tr></table></figure></p>
<p>启动haproxy<br>     /usr/local/haproxy/haproxy.sh start<br>     查看进程ps –ef | grep haproxy已经运行</p>
<h3 id="验证-1">验证</h3><p>多次访问<a href="http://192.168.0.24" target="_blank" rel="external">http://192.168.0.24</a> 显示相应页面即说明负载成功<br>访问<a href="http://192.168.0.24:8080/haproxy-stats" target="_blank" rel="external">http://192.168.0.24:8080/haproxy-stats</a>  查看当前负载状态<br>默认用户admin 密码admin</p>
<h3 id="功能测试-1">功能测试</h3><p>负载均衡测试<br>多次访问<a href="http://192.168.0.24" target="_blank" rel="external">http://192.168.0.24</a> 显示realserver ip address 在192.168.0.14和<br>192.168.0.15之间切换<br>主备切换测试<br>主192.168.0.9上执行service heartbeat stop<br>虚IP 192.168.0.24漂移到192.168.0.10（备）上，访问服务<a href="http://192.168.0.24" target="_blank" rel="external">http://192.168.0.24</a> 正常<br>主192.168.0.9上执行service heartbeat start<br>虚IP 192.168.0.24漂移回192.168.0.9（主）上，访问服务<a href="http://192.168.0.24" target="_blank" rel="external">http://192.168.0.24</a> 正常</p>
<h3 id="性能测试-1">性能测试</h3><p>http性能测试<br>http_load<br>参数说明 –p  并发用户数 –f  总的访问次数 urllist1 <a href="http://192.168.0.24" target="_blank" rel="external">http://192.168.0.24</a><br>测试1：<br>[root@HA010 ~]# http_load -p 1000 -f 20000 urllist1<br>20000 fetches, 1000 max parallel, 5.4e+06 bytes, in 5.08898 seconds<br>270 mean bytes/connection<br>3930.06 fetches/sec, 1.06112e+06 bytes/sec<br>msecs/connect: 2.59386 mean, 3000.77 max, 0.079 min<br>msecs/first-response: 143.209 mean, 3246.75 max, 1.292 min<br>HTTP response codes:<br>  code 200 – 20000<br>测试2：<br>[root@HA010 ~]# http_load -p 1000 -f 30000 urllist1<br>30000 fetches, 1000 max parallel, 8.1e+06 bytes, in 8.2654 seconds<br>270 mean bytes/connection<br>3629.59 fetches/sec, 979989 bytes/sec<br>msecs/connect: 0.348845 mean, 1.385 max, 0.08 min<br>msecs/first-response: 145.923 mean, 6260.67 max, 5.663 min<br>HTTP response codes:<br>  code 200 – 30000<br>测试3<br>http_load -p 1000 -f 50000 urllist1<br>总访问次数50000 并发1000 导致haproxy服务异常，realserver TCP连接大量time wait<br>Siege<br>参数说明 –c 并发用户数量 –r 重复测试次数 urllist1 <a href="http://192.168.0.24" target="_blank" rel="external">http://192.168.0.24</a><br>测试1：<br>[root@HA010 ~]# siege -c 1000 -r 20 -f urllist1<br><strong> SIEGE 2.72
</strong> Preparing 1000 concurrent users for battle.<br>The server is now under siege..      done.</p>
<p>Transactions:                  20000 hits<br>Availability:                 100.00 %<br>Elapsed time:                  19.25 secs<br>Data transferred:               5.15 MB<br>Response time:                  0.08 secs<br>Transaction rate:            1038.96 trans/sec<br>Throughput:                     0.27 MB/sec<br>Concurrency:                   78.64<br>Successful transactions:       20000<br>Failed transactions:               0<br>Longest transaction:            3.24<br>Shortest transaction:           0.00<br>测试2：<br>[root@HA010 ~]# siege -c 1000 -r 30 -f urllist1<br>*<em> SIEGE 2.72<br>*</em> Preparing 1000 concurrent users for battle.<br>The server is now under siege..      done.</p>
<p>Transactions:                  30000 hits<br>Availability:                 100.00 %<br>Elapsed time:                  26.16 secs<br>Data transferred:               7.72 MB<br>Response time:                  0.06 secs<br>Transaction rate:            1146.79 trans/sec<br>Throughput:                     0.30 MB/sec<br>Concurrency:                   65.63<br>Successful transactions:       30000<br>Failed transactions:               0<br>Longest transaction:            3.15<br>Shortest transaction:           0.00<br>测试3：<br>[root@HA010 ~]# siege -c 1000 -r 50 -f urllist1<br>*<em> SIEGE 2.72<br>*</em> Preparing 1000 concurrent users for battle.<br>The server is now under siege…[error] socket: unable to connect sock.c:222: Connection timed out<br>[error] socket: unable to connect sock.c:222: Connection timed out<br>siege aborted due to excessive socket failure; you<br>can change the failure threshold in $HOME/.siegerc</p>
<p>Transactions:                  37886 hits<br>Availability:                  95.08 %<br>Elapsed time:                  58.34 secs<br>Data transferred:               9.95 MB<br>Response time:                  0.42 secs<br>Transaction rate:             649.40 trans/sec<br>Throughput:                     0.17 MB/sec<br>Concurrency:                  275.07<br>Successful transactions:       37886<br>Failed transactions:            1960<br>Longest transaction:           18.00<br>Shortest transaction:           0.00<br>5%访问无法响应<br>总访问次数50000 并发1000 导致haproxy服务异常，realserver TCP连接大量time wait</p>
<h2 id="Ospf测试">Ospf测试</h2><h3 id="部署实施-2">部署实施</h3><p>安装<br>Web服务器192.168.0.14、192.168.0.15上安装quagga软件<br>Yum install quagga</p>
<h3 id="配置-2">配置</h3><p>配置web服务器quagga<br>使用root用户登录192.168.0.14和192.168.0.15<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">cd /etc/quagga</span><br><span class="line">cp ospfd.conf.sample ospfd.conf</span><br><span class="line">chkconfig zebra on</span><br><span class="line">chkconfig ospfd on</span><br><span class="line">service zebra start</span><br><span class="line">service ospfd start</span><br><span class="line">telnet localhost ospfd</span><br><span class="line">输入默认密码zebra</span><br><span class="line">ospfd&gt; en</span><br><span class="line">ospfd<span class="comment"># conf t</span></span><br><span class="line">ospfd(config)<span class="comment"># router ospf</span></span><br><span class="line">ospfd(config-router)<span class="comment"># router-id 192.168.2.66</span></span><br><span class="line">ospfd(config-router)<span class="comment"># network 192.168.0.23/32 area 0.0.0.0(lo IP)</span></span><br><span class="line">ospfd(config-router)<span class="comment"># network 192.168.2.64/30 area 0.0.0.0（接口IP）</span></span><br><span class="line">ospfd(config-router)<span class="comment">#end</span></span><br><span class="line">ospfd<span class="comment">#wr</span></span><br></pre></td></tr></table></figure></p>
<p>配置交换机端<br>根据交换机类型配置ospf与主机quagga建立ospf邻居关系<br>配置主机<br>使用root用户分别在2台web服务上执行以下命令<br>ifconfig lo:0 192.168.0.23 netmask 255.255.255.255 up</p>
<h3 id="验证-2">验证</h3><p>多次访问<a href="http://192.168.0.23" target="_blank" rel="external">http://192.168.0.23</a> 显示相应页面即说明负载成功</p>
<h3 id="功能测试-2">功能测试</h3><p>负载均衡测试<br>多次访问<a href="http://192.168.0.23" target="_blank" rel="external">http://192.168.0.23</a> 显示realserver ip address 在192.168.0.14和<br>192.168.0.15之间切换<br>服务切换测试<br>Down掉192.168.0.14/15上的服务IP 192.168.0.23可以正常访问应用</p>
<h3 id="性能测试-2">性能测试</h3><p>http性能测试<br>http_load<br>参数说明 –p  并发用户数 –f  总的访问次数 urllist1 <a href="http://192.168.0.23" target="_blank" rel="external">http://192.168.0.23</a><br>        测试1：<br>[root@HA010 ~]# http_load -p 1000 -f 20000 urllist2<br>20000 fetches, 1000 max parallel, 5.4e+06 bytes, in 5.16173 seconds<br>270 mean bytes/connection<br>3874.67 fetches/sec, 1.04616e+06 bytes/sec<br>msecs/connect: 128.888 mean, 3001.72 max, 0.068 min<br>msecs/first-response: 25.953 mean, 3031.86 max, 0.63 min<br>HTTP response codes:<br>  code 200 – 20000<br>测试2：<br>[root@HA010 ~]# http_load -p 1000 -f 30000 urllist2<br>30000 fetches, 1000 max parallel, 8.1e+06 bytes, in 5.72167 seconds<br>270 mean bytes/connection<br>5243.23 fetches/sec, 1.41567e+06 bytes/sec<br>msecs/connect: 84.9997 mean, 3001.48 max, 0.062 min<br>msecs/first-response: 18.0883 mean, 2813.84 max, 0.605 min<br>HTTP response codes:<br>  code 200 – 30000<br>测试3：<br>[root@HA010 ~]# http_load -p 1000 -f 50000 urllist2<br>50000 fetches, 1000 max parallel, 1.35e+07 bytes, in 8.0187 seconds<br>270 mean bytes/connection<br>6235.43 fetches/sec, 1.68356e+06 bytes/sec<br>msecs/connect: 101.749 mean, 3001.27 max, 0.07 min<br>msecs/first-response: 16.8017 mean, 1964.43 max, 0.601 min<br>HTTP response codes:<br>  code 200 – 50000<br>总访问次数50000 并发1000，有TCP time wait，但http_load返回正常<br>测试4：<br>[root@HA010 ~]# http_load -p 1000 -f 100000 urllist2<br>总访问次数100000 并发1000 导致TCP连接大量time wait</p>
<p>Siege<br>参数说明 –c 并发用户数量 –r 重复测试次数 urllist1 <a href="http://192.168.0.23" target="_blank" rel="external">http://192.168.0.23</a><br>测试1：<br>[root@HA010 ~]# siege -c 1000 -r 20 -f urllist2<br><strong> SIEGE 2.72
</strong> Preparing 1000 concurrent users for battle.<br>The server is now under siege..      done.</p>
<p>Transactions:                  20000 hits<br>Availability:                 100.00 %<br>Elapsed time:                  19.16 secs<br>Data transferred:               5.15 MB<br>Response time:                  0.03 secs<br>Transaction rate:            1043.84 trans/sec<br>Throughput:                     0.27 MB/sec<br>Concurrency:                   30.30<br>Successful transactions:       20000<br>Failed transactions:               0<br>Longest transaction:            3.01<br>Shortest transaction:           0.00<br>测试2：<br>[root@HA010 ~]# siege -c 1000 -r 30 -f urllist2<br><strong> SIEGE 2.72
</strong> Preparing 1000 concurrent users for battle.<br>The server is now under siege..      done.</p>
<p>Transactions:                  30000 hits<br>Availability:                 100.00 %<br>Elapsed time:                  24.14 secs<br>Data transferred:               7.72 MB<br>Response time:                  0.01 secs<br>Transaction rate:            1242.75 trans/sec<br>Throughput:                     0.32 MB/sec<br>Concurrency:                   15.34<br>Successful transactions:       30000<br>Failed transactions:               0<br>Longest transaction:            3.00<br>Shortest transaction:           0.00<br>测试3：<br>[root@HA010 ~]# siege -c 1000 -r 50 -f urllist2<br><strong> SIEGE 2.72
</strong> Preparing 1000 concurrent users for battle.<br>The server is now under siege..      done.</p>
<p>Transactions:                  50000 hits<br>Availability:                 100.00 %<br>Elapsed time:                  37.18 secs<br>Data transferred:              12.87 MB<br>Response time:                  0.01 secs<br>Transaction rate:            1344.81 trans/sec<br>Throughput:                     0.35 MB/sec<br>Concurrency:                    9.42<br>Successful transactions:       50000<br>Failed transactions:               0<br>Longest transaction:            3.01<br>Shortest transaction:           0.00<br>总访问次数50000 并发1000，有TCP time wait，但siege返回正常<br>测试4：<br>[root@HA010 ~]# siege -c 1000 -r 100 -f urllist2<br><strong> SIEGE 2.72
</strong> Preparing 1000 concurrent users for battle.<br>The server is now under siege..      done.</p>
<p>Transactions:                 100000 hits<br>Availability:                 100.00 %<br>Elapsed time:                  66.28 secs<br>Data transferred:              25.75 MB<br>Response time:                  0.01 secs<br>Transaction rate:            1508.75 trans/sec<br>Throughput:                     0.39 MB/sec<br>Concurrency:                    9.66<br>Successful transactions:      100000<br>Failed transactions:               0<br>Longest transaction:            3.02<br>Shortest transaction:           0.00<br>总访问次数100000 并发1000，有TCP time wait，但siege返回正常</p>
<p>测试用PHP主页代码<br>  <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="preprocessor">&lt;?php</span></span><br><span class="line"></span><br><span class="line">session_start();</span><br><span class="line"></span><br><span class="line"><span class="variable">$_SESSION</span>[<span class="string">'time'</span>] =date(<span class="string">"Y:m:d:H:s"</span>,time());</span><br><span class="line"></span><br><span class="line"><span class="keyword">echo</span> <span class="string">"time"</span>.<span class="string">"&lt;font color=red&gt;"</span>.<span class="variable">$_SESSION</span>[<span class="string">'time'</span>].<span class="string">"&lt;/font&gt;"</span>.<span class="string">"&lt;br&gt;"</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">echo</span> <span class="string">"realserver ip address"</span>.<span class="string">"&lt;font color=red&gt;"</span>.<span class="variable">$_SERVER</span>[<span class="string">'SERVER_ADDR'</span>].<span class="string">"&lt;/font&gt;"</span>.<span class="string">"&lt;br&gt;"</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">echo</span> <span class="string">"local address"</span>.<span class="string">"&lt;font color=red&gt;"</span>.<span class="variable">$_SERVER</span>[<span class="string">'SERVER_NAME'</span>].<span class="string">"&lt;/font&gt;"</span>.<span class="string">"&lt;br&gt;"</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">echo</span> <span class="string">"SESSIONNAME"</span>.<span class="string">"&lt;font color=red&gt;"</span>.session_name().<span class="string">"&lt;/font&gt;"</span>.<span class="string">"&lt;br&gt;"</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">echo</span> <span class="string">"SESSIONID"</span>.<span class="string">"&lt;font color=red&gt;"</span>.session_id().<span class="string">"&lt;/font&gt;"</span>.<span class="string">"&lt;br&gt;"</span>;</span><br><span class="line"></span><br><span class="line"><span class="preprocessor">?&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>查看主机TCP连接情况<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -nat|awk <span class="string">'&#123;print awk $NF&#125;'</span>|sort|uniq -c|sort -n</span><br></pre></td></tr></table></figure></p>
]]></content>
    <summary type="html">
    <![CDATA[通过分析lvs、haproxy、ospf负载均衡的特点，确定应用场景]]>
    
    </summary>
    
      <category term="haproxy" scheme="http://www.anste.com/tags/haproxy/"/>
    
      <category term="lvs" scheme="http://www.anste.com/tags/lvs/"/>
    
      <category term="ospf" scheme="http://www.anste.com/tags/ospf/"/>
    
      <category term="Linux" scheme="http://www.anste.com/categories/Linux/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Openstack CentOS镜像制作教程]]></title>
    <link href="http://www.anste.com/2015/06/10/Openstack-CentOS/"/>
    <id>http://www.anste.com/2015/06/10/Openstack-CentOS/</id>
    <published>2015-06-10T06:02:05.000Z</published>
    <updated>2015-06-10T07:02:56.787Z</updated>
    <content type="html"><![CDATA[<h1 id="1-_CentOS6">1.    CentOS6</h1><p>参考：<a href="http://docs.openstack.org/zh_CN/image-guide/content/centos-image.html" target="_blank" rel="external">http://docs.openstack.org/zh_CN/image-guide/content/centos-image.html</a><br><strong>注意：按照本教程制作的镜像默认是允许root等用户使用密码登陆</strong></p>
<h2 id="1)_oz安装">1)    oz安装</h2><p>本文档使用192.168.9.100（CentOS6.6）制作各种镜像<br>下载centos6 镜像iso文件<br>添加epel安装源<br>yum install –y oz</p>
<h2 id="2)_修改oz-conf">2)    修改oz.conf</h2>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[root<span class="decorator">@salt oz]# cat /etc/oz/oz.cfg</span></span><br><span class="line">[paths]</span><br><span class="line">output_dir = /var/lib/libvirt/images</span><br><span class="line">data_dir = /var/lib/oz</span><br><span class="line">screenshot_dir = /var/lib/oz/screenshots</span><br><span class="line"><span class="comment"># sshprivkey = /etc/oz/id_rsa-icicle-gen</span></span><br><span class="line"></span><br><span class="line">[libvirt]</span><br><span class="line">uri = qemu:///system</span><br><span class="line">image_type = qcow2</span><br><span class="line"><span class="comment"># type = kvm</span></span><br><span class="line"><span class="comment"># bridge_name = virbr0</span></span><br><span class="line"><span class="comment"># cpus = 1</span></span><br><span class="line"><span class="comment"># memory = 1024</span></span><br><span class="line"></span><br><span class="line">[cache]</span><br><span class="line">original_media = yes</span><br><span class="line">modified_media = no</span><br><span class="line">jeos = no</span><br><span class="line"></span><br><span class="line">[icicle]</span><br><span class="line">safe_generation = no</span><br></pre></td></tr></table></figure>
<h2 id="3)_生成ks文件">3)    生成ks文件</h2><p>vi /etc/oz/centos6.6.ks 写入以下内容<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#version=DEVEL</span></span><br><span class="line"><span class="comment"># Firewall configuration</span></span><br><span class="line">firewall --disabled</span><br><span class="line">repo --name=<span class="string">"centosbase"</span> --baseurl=http://repourl/centos/<span class="number">6</span>/os/x86_64/ <span class="comment">#更改成自己环境里的repo地址或者使用官方repo源</span></span><br><span class="line">repo --name=<span class="string">"centosupdate"</span> --baseurl=http://repourl/centos/<span class="number">6</span>/updates/x86_64/ <span class="comment">#更改成自己环境里的repo地址或者使用官方repo源</span></span><br><span class="line">repo --name=<span class="string">"epel"</span> --baseurl=http://repourl/fedora-epel/<span class="number">6</span>Server/x86_64/ <span class="comment">#更改成自己环境里的repo地址或者使用官方repo源</span></span><br><span class="line">repo --name=<span class="string">"puppetlab"</span> --baseurl=http://repourl/puppetlabs/el/<span class="number">6</span>/products/x86_64/ <span class="comment">#更改成自己环境里的repo地址或者使用官方repo源</span></span><br><span class="line"><span class="comment"># Root password</span></span><br><span class="line">rootpw --iscrypted $<span class="number">1</span>$sNmInJMT$yUNqi7p34UcrNud8N.t3l/</span><br><span class="line"><span class="comment"># System authorization information</span></span><br><span class="line">auth --useshadow --enablemd5</span><br><span class="line"><span class="comment">#use text mode install</span></span><br><span class="line">text</span><br><span class="line"><span class="comment">#firstboot</span></span><br><span class="line">firstboot --disable</span><br><span class="line"><span class="comment"># System keyboard</span></span><br><span class="line">keyboard us</span><br><span class="line"><span class="comment"># System language</span></span><br><span class="line">lang en_US.UTF-<span class="number">8</span></span><br><span class="line"><span class="comment"># SELinux configuration</span></span><br><span class="line">selinux --disabled</span><br><span class="line"><span class="comment"># Installation logging level</span></span><br><span class="line">logging --level=info</span><br><span class="line"><span class="comment"># Reboot after installation</span></span><br><span class="line">reboot</span><br><span class="line"><span class="comment"># System services</span></span><br><span class="line">services --disabled=<span class="string">"iptables,ip6tables,postfix,avahi-daemon,iscsi,iscsid,firstboot,kdump"</span> --enabled=<span class="string">"network,sshd,rsyslog,tuned,acpid,puppet"</span></span><br><span class="line"><span class="comment"># System timezone</span></span><br><span class="line">timezone Asia/Shanghai</span><br><span class="line"><span class="comment"># Network information</span></span><br><span class="line">network  --bootproto=dhcp --device=eth0 --onboot=on</span><br><span class="line"><span class="comment"># System bootloader configuration</span></span><br><span class="line">bootloader --append=<span class="string">"console=ttyS0,115200n8 console=tty0"</span> --location=mbr --driveorder=<span class="string">"sda"</span> --timeout=<span class="number">1</span></span><br><span class="line"><span class="comment"># Clear the Master Boot Record</span></span><br><span class="line">zerombr</span><br><span class="line"><span class="comment"># Partition clearing information</span></span><br><span class="line">clearpart --all</span><br><span class="line"><span class="comment"># Disk partitioning information</span></span><br><span class="line"><span class="comment">#part / --fstype="ext4" --grow --size=1</span></span><br><span class="line">part / --fstype ext4 --size=<span class="number">512</span> --grow</span><br><span class="line"></span><br><span class="line">%packages --nobase --excludedocs</span><br><span class="line">ntpdate</span><br><span class="line">openssh-clients</span><br><span class="line">acpid</span><br><span class="line">iotop</span><br><span class="line">ftp</span><br><span class="line">iptraf</span><br><span class="line">telnet</span><br><span class="line">gcc</span><br><span class="line">automake</span><br><span class="line">autoconf</span><br><span class="line">libtool</span><br><span class="line">gcc-c++</span><br><span class="line">openssl-devel</span><br><span class="line">xinetd</span><br><span class="line">quagga</span><br><span class="line">tmux</span><br><span class="line">puppet</span><br><span class="line">wget</span><br><span class="line">vim</span><br><span class="line">cloud-init</span><br><span class="line">cloud-utils</span><br><span class="line">cloud-utils-growpart</span><br><span class="line">dracut-modules-growroot</span><br><span class="line">%end</span><br><span class="line"></span><br><span class="line">%post</span><br><span class="line"></span><br><span class="line"><span class="comment"># make sure firstboot doesn't start</span></span><br><span class="line">echo <span class="string">"RUN_FIRSTBOOT=NO"</span> &gt; /etc/sysconfig/firstboot</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOL &gt;&gt; /etc/rc.local</span><br><span class="line"><span class="keyword">if</span> [ ! -d /root/.ssh ] ; then</span><br><span class="line">    mkdir -p /root/.ssh</span><br><span class="line">    chmod <span class="number">0700</span> /root/.ssh</span><br><span class="line">    restorecon /root/.ssh</span><br><span class="line">fi</span><br><span class="line">EOL</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOL &gt;&gt; /etc/ssh/sshd_config</span><br><span class="line">UseDNS no</span><br><span class="line">EOL</span><br><span class="line"></span><br><span class="line"><span class="comment"># grub</span></span><br><span class="line">ln -s /boot/grub/grub.conf /etc/grub.conf</span><br><span class="line"></span><br><span class="line"><span class="comment">#make sure permit ssh password login</span></span><br><span class="line">sed -i <span class="string">'s/PasswordAuthentication no/PasswordAuthentication yes/g'</span> /etc/ssh/sshd_config</span><br><span class="line"></span><br><span class="line"><span class="comment"># allow sudo powers to cloud-user</span></span><br><span class="line">echo -e <span class="string">'centos\tALL=(ALL)\tNOPASSWD: ALL'</span> &gt;&gt; /etc/sudoers</span><br><span class="line"></span><br><span class="line"><span class="comment"># disable zeroconf</span></span><br><span class="line">echo <span class="string">"NOZEROCONF=yes"</span> &gt;&gt; /etc/sysconfig/network</span><br><span class="line"></span><br><span class="line"><span class="comment"># set virtual-guest as default profile for tuned</span></span><br><span class="line">echo <span class="string">"virtual-guest"</span> &gt; /etc/tune-profiles/active-profile</span><br><span class="line"></span><br><span class="line"><span class="comment">#init network config</span></span><br><span class="line"><span class="comment"># set eth0 to recover from dhcp errors</span></span><br><span class="line">cat &gt; /etc/sysconfig/network-scripts/ifcfg-eth0 &lt;&lt; EOF</span><br><span class="line">DEVICE=<span class="string">"eth0"</span></span><br><span class="line">BOOTPROTO=<span class="string">"dhcp"</span></span><br><span class="line">ONBOOT=<span class="string">"yes"</span></span><br><span class="line">TYPE=<span class="string">"Ethernet"</span></span><br><span class="line">USERCTL=<span class="string">"yes"</span></span><br><span class="line">PEERDNS=<span class="string">"yes"</span></span><br><span class="line">IPV6INIT=<span class="string">"no"</span></span><br><span class="line">PERSISTENT_DHCLIENT=<span class="string">"1"</span></span><br><span class="line">EOF</span><br><span class="line"><span class="comment"># prevent udev rules from remapping nics</span></span><br><span class="line">rm -f /etc/udev/rules.d/<span class="number">70</span>-persistent-net.rules</span><br><span class="line"></span><br><span class="line"><span class="comment">#setup getty on ttyS0</span></span><br><span class="line">echo <span class="string">"ttyS0"</span> &gt;&gt; /etc/securetty</span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/init/ttyS0.conf</span><br><span class="line">start on stopped rc RUNLEVEL=[<span class="number">2345</span>]</span><br><span class="line">stop on starting runlevel [<span class="number">016</span>]</span><br><span class="line">respawn</span><br><span class="line">instance /dev/ttyS0</span><br><span class="line"><span class="keyword">exec</span> /sbin/agetty /dev/ttyS0 <span class="number">115200</span> vt100-nav</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># clean up installation logs"</span></span><br><span class="line">yum clean all</span><br><span class="line">rm -rf /var/log/yum.log</span><br><span class="line">rm -rf /var/lib/yum/*</span><br><span class="line">rm -rf /root/install.log</span><br><span class="line">rm -rf /root/install.log.syslog</span><br><span class="line">rm -rf /root/anaconda-ks.cfg</span><br><span class="line">rm -rf /var/log/anaconda*</span><br><span class="line">%end</span><br></pre></td></tr></table></figure></p>
<h2 id="4)_生成tdl文件">4)    生成tdl文件</h2><p>vi /etc/oz/centos6.6.tdl 更改成以下内容：<br>[root@salt home]# cat /etc/oz/centos6.6.tdl<br>  <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&lt;template&gt;</span><br><span class="line">   &lt;name&gt;CentOS_6.6_x86_64&lt;/name&gt;</span><br><span class="line">   &lt;description&gt;CentOS 6.6 x86_64 template&lt;/description&gt;</span><br><span class="line">   &lt;os&gt;</span><br><span class="line">      &lt;name&gt;CentOS-6&lt;/name&gt;</span><br><span class="line">      &lt;version&gt;6&lt;/version&gt;</span><br><span class="line">      &lt;arch&gt;x86_64&lt;/arch&gt;</span><br><span class="line">      &lt;install type='url'&gt;</span><br><span class="line">         &lt;url&gt;http://cobblerURL/cobbler/ks_mirror/CenOS_6.5-x86_64/&lt;/url&gt;</span><br><span class="line">      &lt;/install&gt;</span><br><span class="line">   &lt;/os&gt;</span><br><span class="line">  &lt;disk&gt;</span><br><span class="line">    &lt;size&gt;10&lt;/size&gt;</span><br><span class="line">  &lt;/disk&gt;</span><br><span class="line">&lt;/template&gt;</span><br></pre></td></tr></table></figure></p>
<h2 id="5)_制作centos6-6镜像">5)    制作centos6.6镜像</h2><p>使用root用户执行以下命令<br>oz-install -p -u -d3 -a /etc/oz/centos6.6.ks /etc/oz/centos6.6.tdl<br>执行后，开始自动生成镜像。<br>安装过程可以登录虚拟机所在宿主机使用 virt-manager实时查看新建的kvm虚拟机</p>
<h2 id="6)_修改镜像">6)    修改镜像</h2><p>使用virt-manager打开生成的qcow2的镜像文件路径为/var/lib/libvirt/images，<br>进入系统（耐心等待）<br>使用root配置临时IP地址192.168.9.13、路由、DNS、SSH等<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ifconfig eth0 <span class="number">192.168</span>.9.13 <span class="number">255.255</span>.255.128 up</span><br><span class="line">route add -net <span class="number">0.0</span>.0.0/<span class="number">0</span> gw <span class="number">192.168</span>.9.1 dev eth0</span><br><span class="line">vi /etc/resolv.conf </span><br><span class="line">nameserver <span class="number">192.168</span>.10.87</span><br><span class="line">vi /etc/ssh/sshd_config</span><br><span class="line">PasswordAuthentication yes  重启sshd</span><br><span class="line">passwd root 配置root默认密码</span><br></pre></td></tr></table></figure></p>
<h2 id="7)_yum源配置">7)    yum源配置</h2><p>Root ssh登陆192.168.9.100，执行以下命令复制yum 源相关文件<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp /etc/pki/rpm-gpg/RPM-GPG-KEY-* <span class="number">192.168</span>.9.13:/etc/pki/rpm-gpg/</span><br><span class="line">scp /etc/yum.repos.d/*.repo <span class="number">192.168</span>.9.13:/etc/yum.repos.d/</span><br></pre></td></tr></table></figure></p>
<h2 id="8)_cloud-init修改">8)    cloud.init修改</h2><p>vi /etc/cloud/cloud.init<br>修改以下内容<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">disable_root: <span class="number">0</span> <span class="comment">#是否允许root登陆  1 禁止 0 允许</span></span><br><span class="line">ssh_pwauth:  <span class="number">1</span>  <span class="comment">#是否允许密码登陆  1 允许 0 禁止</span></span><br><span class="line">system_info:</span><br><span class="line">  distro: rhel</span><br><span class="line">  default_user:</span><br><span class="line">    name: centos <span class="comment"># 默认openstack新增用户名</span></span><br><span class="line">  paths:</span><br><span class="line">    cloud_dir: /var/lib/cloud</span><br><span class="line">    templates_dir: /etc/cloud/templates</span><br><span class="line">  ssh_svcname: sshd</span><br></pre></td></tr></table></figure></p>
<h2 id="9)_修改grub，将系统日志重定向到openstack_console">9)    修改grub，将系统日志重定向到openstack console</h2><p>vi /boot/grub/menu.lst 删除 rhgb quiet并添加console=tty0 console=ttyS0,115200n8</p>
<h2 id="10)_其他初始化配置">10)    其他初始化配置</h2><p>crontab –e 添加NTP服务同步机制<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span> <span class="number">9</span> * * * /usr/sbin/ntpdate <span class="number">192.168</span>.253.4</span><br></pre></td></tr></table></figure></p>
<p>变更操作系统时区<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rm -f /etc/localtime</span><br><span class="line">ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br></pre></td></tr></table></figure></p>
<p>删除网卡物理信息<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -f /etc/udev/rules.d/<span class="number">70</span>-persistent-net.rules</span><br></pre></td></tr></table></figure></p>
<p>删除其他临时信息和日志<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">rm -rf /tmp/*</span><br><span class="line">rm -f /var/log/wtmp /var/log/btmp</span><br><span class="line">rm -rf /var/log/yum.log</span><br><span class="line">rm -rf /var/lib/yum/*</span><br><span class="line">rm -rf /root/install.log</span><br><span class="line">rm -rf /root/install.log.syslog</span><br><span class="line">rm -rf /root/anaconda-ks.cfg</span><br><span class="line">rm -rf /var/log/anaconda*</span><br><span class="line">history -c</span><br></pre></td></tr></table></figure></p>
<p>关闭虚拟机<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shutdown -h now</span><br></pre></td></tr></table></figure></p>
<h2 id="11)_压缩上传镜像">11)    压缩上传镜像</h2><p>root登陆192.168.9.100后执行以下命令压缩镜像<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">qemu-img convert -c /var/lib/libvirt/images/CentOS_6.6_x86_64.qcow2 -O qcow2 /home/CentOS_6.6_x86_64.qcow2</span><br></pre></td></tr></table></figure></p>
<p>压缩完毕后将压缩镜像拷贝到192.168.13.5（openstack Controller节点）<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp /home/CentOS_6.6_x86_64.qcow2 <span class="number">192.168</span>.13.5:/tmp</span><br></pre></td></tr></table></figure></p>
<p>登陆到192.168.13.5（openstack Controller节点），执行以下命令<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">source /root/openrc</span><br><span class="line">glance image-create --name CentOS_6.6_x86_64 --disk-format=qcow2 --container-format=bare --<span class="keyword">is</span>-public=<span class="keyword">True</span> --progress --file /tmp/CentOS_6.6_x86_64.qcow2</span><br></pre></td></tr></table></figure></p>
<p>至此，centos6.6镜像已经上传到openstack镜像源中。</p>
<h2 id="12)_CentOS7镜像">12)    CentOS7镜像</h2><p>无相关制作教程，centos7下载官方镜像使用guestfish修改即可<br><a href="http://cloud.centos.org/centos/7/images/" target="_blank" rel="external">http://cloud.centos.org/centos/7/images/</a><br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">guestfish --rw -a CentOS_7_x86_64.qcow2</span><br><span class="line">&gt;&lt;fs&gt; run</span><br><span class="line">&gt;&lt;fs&gt; list-filesystems</span><br><span class="line">/dev/sda1: xfs</span><br><span class="line">&gt;&lt;fs&gt; mount /dev/sda1 /</span><br><span class="line">&gt;&lt;fs&gt; vi /etc/cloud/cloud.cfg</span><br><span class="line">disable_root: <span class="number">0</span></span><br><span class="line">ssh_pwauth:   <span class="number">1</span> </span><br><span class="line"> touch /var/spool/cron/root</span><br><span class="line">&gt;&lt;fs&gt; vi /var/spool/cron/root</span><br><span class="line"><span class="number">0</span> <span class="number">9</span> * * * /usr/sbin/ntpdate <span class="number">192.168</span>.253.4</span><br><span class="line">&gt;&lt;fs&gt; rm /etc/localtime</span><br><span class="line">&gt;&lt;fs&gt; ln /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br><span class="line">&gt;&lt;fs&gt; vi /etc/shadow粘贴到root：后（使用其他centos上用openssl passwd -<span class="number">1</span> <span class="string">"yourpassword"</span> 产生root加密后的密码 ）</span><br><span class="line">&gt;&lt;fs&gt; exit</span><br></pre></td></tr></table></figure></p>
]]></content>
    <summary type="html">
    <![CDATA[制作openstack使用的CentOS6、CentOS7镜像文件教程]]>
    
    </summary>
    
      <category term="linux" scheme="http://www.anste.com/tags/linux/"/>
    
      <category term="openstack" scheme="http://www.anste.com/tags/openstack/"/>
    
      <category term="openstack" scheme="http://www.anste.com/categories/openstack/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[部署Foreman+Puppet自动化配置管理系统]]></title>
    <link href="http://www.anste.com/2015/06/09/Foreman-Puppet/"/>
    <id>http://www.anste.com/2015/06/09/Foreman-Puppet/</id>
    <published>2015-06-09T07:17:57.000Z</published>
    <updated>2015-06-10T06:47:07.843Z</updated>
    <content type="html"><![CDATA[<h1 id="概述">概述</h1><p>Puppet是用于自动化管理服务器的开源软件，主要用来做配置管理，批量推送配置到所有服务器。<br>项目主页：<a href="http://www.puppetlabs.com/" target="_blank" rel="external">http://www.puppetlabs.com/</a><br>foreman 是服务器生命周期管理系统，可以用来做为puppet的前端查看puppet同步信息以及服务器各项物理参数。<br>项目主页：<a href="http://www.theforeman.org" target="_blank" rel="external">http://www.theforeman.org</a><br>Pssh是开源的并行批量SSH工具包，包括pssh、pscp、prsync、pnuke、pslurp等工具。用于弥补puppet命令行的短板。<br>项目主页：<a href="https://code.google.com/p/parallel-ssh/" target="_blank" rel="external">https://code.google.com/p/parallel-ssh/</a></p>
<h1 id="部署">部署</h1><h2 id="实施环境">实施环境</h2><h3 id="硬件环境">硬件环境</h3><p>IP：192.168.10.91（生产网段）<br>CPU：QEMU Virtual CPU version (cpu64-rhel6) （KVM）<br>内存：4G<br>硬盘：50G</p>
<p>IP：192.168.10.43（puppet网段）<br>CPU：Intel(R) Xeon(R) CPU           X5670  @ 2.93GHz<br>内存：32G<br>硬盘：300G</p>
<h3 id="软件环境">软件环境</h3><p>IP：192.168.10.91（生产网段）<br>操作系统：CentOS release 6.4(Final)<br>内核版本：2.6.32-279.19.1.el6.x86_64<br>Ruby版本：1.8.7（1.9版本不兼容）</p>
<p>IP：192.168.10.43（puppet网段）<br>操作系统：CentOS release 6.4 (Final)<br>内核版本：2.6.32-279.19.1.el6.x86_64<br>Ruby版本：1.8.7（1.9版本不兼容）</p>
<h2 id="安装配置">安装配置</h2><h3 id="yum源配置">yum源配置</h3>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum –y install http://yum.theforeman.org/releases/latest/el6/x86_64/foreman-release.rpm</span><br><span class="line">yum -y install http://dl.fedoraproject.org/pub/epel/<span class="number">6</span>/x86_64/epel-release-<span class="number">6</span>-<span class="number">8.</span>noarch.rpm</span><br><span class="line">yum –y install http://yum.puppetlabs.com/el/<span class="number">6</span>/products/x86_64/puppetlabs-release-<span class="number">6</span>-<span class="number">7.</span>noarch.rpm</span><br></pre></td></tr></table></figure>
<p>增加epel、foreman、puppet yum源</p>
<h3 id="pssh安装">pssh安装</h3>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">wget   https://parallel-ssh.googlecode.com/files/pssh-<span class="number">2.3</span>.1.tar.gz</span><br><span class="line">tar xvzf pssh-<span class="number">2.3</span>.1.tar.gz</span><br><span class="line">cd pssh-<span class="number">2.3</span>.1</span><br><span class="line">./configure</span><br><span class="line">Make</span><br><span class="line">Make install</span><br></pre></td></tr></table></figure>
<h1 id="puppet+foreman安装">puppet+foreman安装</h1><h2 id="服务器端">服务器端</h2><p>修改hosts<br>Vi /etc/hosts<br>增加192.168.10.91 puppet.yourdomain.cn （生产网段）<br>使用root执行hostname  –f 查看是否生效<br>生效显示：<br>     puppet.yourdomain.cn （生产网段）<br>异常情况请删除/etc/hosts中localhost部分多余内容，只保留如下：<br>127.0.0.1 localhost<br>::1 localhost</p>
<h3 id="安装puppet客户端">安装puppet客户端</h3><p>yum –y install puppet （默认安装3.2.4的客户端）<br>安装foreman+puppet server<br>yum –y install foreman-installer<br>service puppet start (启动puppet客户端用来安装foreman和puppet server)<br>ruby /usr/share/foreman-installer/generate_answers.rb<br>按照提示选择默认配置即可。<br>安装完毕后即完成foreman、foreman-proxy、puppet server的安装。<br>Service puppet stop<br>Chkconfig –level 35 puppet off（客户端只用来安装foreman和puppet server，安装完毕后可以关闭）</p>
<h3 id="启动服务">启动服务</h3><p>修改foreman-proxy配置<br>Vi /etc/foreman-proxy/setting.yaml<br>:trusted_hosts 取消该行注释<br>修改/etc/puppet/autosign.conf<br>*.yourdomain.cn #增加自动签名机制<br>Service foreman-proxy start<br>Service foreman start<br>Service httpd start</p>
<h3 id="检查服务">检查服务</h3><p>访问<a href="https://192.168.10.43" target="_blank" rel="external">https://192.168.10.43</a> 用户名 admin 密码changme<br>增加foreman smart proxy<br>选择more—configuration—Smart Proxies<br>新增puppet或puppet02，URL为<a href="https://puppet.yourdomain.cn:8443或https://puppet02.yourdomain.cn:8443" target="_blank" rel="external">https://puppet.yourdomain.cn:8443或https://puppet02.yourdomain.cn:8443</a></p>
<h2 id="客户端">客户端</h2><p>修改etc/hosts<br>vi /etc/hosts（只有puppet节点客户端需要修改）<br>增加192.168.8.249 puppet02.yourdomain.cn<br>     192.168.10.8 cst-bj-1.yourdomain.cn cst-bj-1（其他主机配置类似hosts）</p>
<h3 id="安装">安装</h3><p>使用root登录192.168.10.43或192.168.10.91<br>Cd pssh<br>pscp –h host.list –o log puppet-2.7.21.tar.gz /root/分发puppet源码包到各节点<br>pscp –h host.list –o log facter-1.X.X.tar.gz /root/ 分发facter源码包到各节点<br>备注：host.list为客户端ip地址表 –o表示日志记录在当前路径log目录下<br>Pssh –h host.list –o log “tar xvzf facter-1.X.X.tar.gz &amp;&amp; cd facter-1.X.X &amp;&amp; ruby install.rb”<br>Pssh –h host.list –o log “tar xvzf puppet-2.7.21.tar.gz &amp;&amp; cd puppet-2.7.21 &amp;&amp; ruby install.rb”</p>
<h3 id="配置">配置</h3><p>编辑puppetd 客户端启动脚本<br>Vi /etc/init.d/puppetd<br>  <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"># puppet        Init script for running the puppet client daemon</span><br><span class="line">#</span><br><span class="line"># Author:       Duane Griffin &lt;d.griffin@psenterprise.com&gt;</span><br><span class="line">#               David Lutterkort &lt;dlutter@redhat.com&gt;</span><br><span class="line">#</span><br><span class="line"># chkconfig: 35 98 02</span><br><span class="line">#</span><br><span class="line"># description: Enables periodic system configuration checks through puppet.</span><br><span class="line"># processname: puppet</span><br><span class="line"># config: /etc/sysconfig/puppet</span><br><span class="line"></span><br><span class="line">PATH=/usr/bin:/sbin:/bin:/usr/sbin</span><br><span class="line">export PATH</span><br><span class="line"></span><br><span class="line">[ -f /etc/sysconfig/puppet ] &amp;&amp; . /etc/sysconfig/puppet</span><br><span class="line">lockfile=$&#123;LOCKFILE-/var/lock/subsys/puppet&#125;</span><br><span class="line">pidfile=$&#123;PIDFILE-/var/lib/puppet/run/agent.pid&#125;</span><br><span class="line">puppetd=$&#123;PUPPETD-/usr/sbin/puppetd&#125;</span><br><span class="line">RETVAL=0</span><br><span class="line"></span><br><span class="line"># Source function library.</span><br><span class="line">. /etc/rc.d/init.d/functions</span><br><span class="line"></span><br><span class="line">PUPPET_OPTS=""</span><br><span class="line">[ -n "$&#123;PUPPET_SERVER&#125;" ] &amp;&amp; PUPPET_OPTS="--server=$&#123;PUPPET_SERVER&#125;"</span><br><span class="line">[ -n "$PUPPET_LOG" ] &amp;&amp; PUPPET_OPTS="$&#123;PUPPET_OPTS&#125; --logdest=$&#123;PUPPET_LOG&#125;"</span><br><span class="line">[ -n "$PUPPET_PORT" ] &amp;&amp; PUPPET_OPTS="$&#123;PUPPET_OPTS&#125; --masterport=$&#123;PUPPET_PORT&#125;"</span><br><span class="line"></span><br><span class="line"># Determine if we can use the -p option to daemon, killproc, and status.</span><br><span class="line"># RHEL &lt; 5 can't.</span><br><span class="line">if status | grep -q -- '-p' 2&gt;/dev/null; then</span><br><span class="line">    daemonopts="--pidfile $pidfile"</span><br><span class="line">    pidopts="-p $pidfile"</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"># Figure out if the system just booted. Let's assume</span><br><span class="line"># boot doesn't take longer than 5 minutes</span><br><span class="line">## Not used for now</span><br><span class="line">##[ -n "$INIT_VERSION" ] &amp;&amp; PUPPET_OPTS="$&#123;PUPPET_OPTS&#125; --fullrun"</span><br><span class="line"></span><br><span class="line">start() &#123;</span><br><span class="line">    echo -n $"Starting puppet: "</span><br><span class="line">    daemon $daemonopts $puppetd $&#123;PUPPET_OPTS&#125; $&#123;PUPPET_EXTRA_OPTS&#125;</span><br><span class="line">    RETVAL=$?</span><br><span class="line">    echo</span><br><span class="line">        [ $RETVAL = 0 ] &amp;&amp; touch $&#123;lockfile&#125;</span><br><span class="line">        return $RETVAL</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">stop() &#123;</span><br><span class="line">    echo -n $"Stopping puppet: "</span><br><span class="line">    killproc $pidopts $puppetd</span><br><span class="line">    RETVAL=$?</span><br><span class="line">    echo</span><br><span class="line">    [ $RETVAL = 0 ] &amp;&amp; rm -f $&#123;lockfile&#125; $&#123;pidfile&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">reload() &#123;</span><br><span class="line">    echo -n $"Restarting puppet: "</span><br><span class="line">    killproc $pidopts $puppetd -HUP</span><br><span class="line">    RETVAL=$?</span><br><span class="line">    echo</span><br><span class="line">    return $RETVAL</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">restart() &#123;</span><br><span class="line">    stop</span><br><span class="line">    start</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">rh_status() &#123;</span><br><span class="line">    status $pidopts $puppetd</span><br><span class="line">    RETVAL=$?</span><br><span class="line">    return $RETVAL</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">rh_status_q() &#123;</span><br><span class="line">    rh_status &gt;/dev/null 2&gt;&amp;1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">genconfig() &#123;</span><br><span class="line">    echo -n $"Generate configuration puppet: "</span><br><span class="line">    $puppetd $&#123;PUPPET_OPTS&#125; $&#123;PUPPET_EXTRA_OPTS&#125; --genconfig</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">case "$1" in</span><br><span class="line">    start)</span><br><span class="line">        start</span><br><span class="line">    ;;</span><br><span class="line">    stop)</span><br><span class="line">        stop</span><br><span class="line">    ;;</span><br><span class="line">    restart)</span><br><span class="line">        restart</span><br><span class="line">    ;;</span><br><span class="line">    reload|force-reload)</span><br><span class="line">        reload</span><br><span class="line">    ;;</span><br><span class="line">    condrestart|try-restart)</span><br><span class="line">        rh_status_q || exit 0</span><br><span class="line">        restart</span><br><span class="line">    ;;</span><br><span class="line">    status)</span><br><span class="line">        rh_status</span><br><span class="line">    ;;</span><br><span class="line">    once)</span><br><span class="line">        shift</span><br><span class="line">        $puppetd -o $&#123;PUPPET_OPTS&#125; $&#123;PUPPET_EXTRA_OPTS&#125; $@</span><br><span class="line">        ;;</span><br><span class="line">    genconfig)</span><br><span class="line">        genconfig</span><br><span class="line">    ;;</span><br><span class="line">    *)</span><br><span class="line">        echo $"Usage: $0 &#123;start|stop|status|restart|reload|force-reload|condrestart|once|genconfig&#125;"</span><br><span class="line">        exit 1</span><br><span class="line">esac</span><br><span class="line"></span><br><span class="line">exit $RETVAL</span><br></pre></td></tr></table></figure></p>
<p>chmod +x /etc/init.d/puppetd<br>编辑vi /etc/sysconfig/puppet<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># The puppetmaster server</span></span><br><span class="line">PUPPET_SERVER=puppet02.yourdomain.cn（或puppet.yourdomain.cn）</span><br><span class="line"></span><br><span class="line"><span class="comment"># If you wish to specify the port to connect to do so here</span></span><br><span class="line">PUPPET_PORT=<span class="number">8140</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Where to log to. Specify syslog to send log messages to the system log.</span></span><br><span class="line">PUPPET_LOG=/var/log/puppet/puppet.log</span><br><span class="line"></span><br><span class="line"><span class="comment"># You may specify other parameters to the puppet client here</span></span><br><span class="line"><span class="comment">#PUPPET_EXTRA_OPTS=--waitforcert=500</span></span><br></pre></td></tr></table></figure></p>
<p>编辑 vi /etc/puppet/puppet.conf<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[agent]</span><br><span class="line">server=puppet02.yourdomain.cn（或puppet.yourdomain.cn）</span><br><span class="line">listen=true</span><br><span class="line">report=true</span><br><span class="line">runinterval=<span class="number">1800</span></span><br></pre></td></tr></table></figure></p>
<h3 id="启动服务-1">启动服务</h3><p>使用root登录192.168.10.43或192.168.10.91<br>cd pssh<br>Pssh –h host.list –P –o log “service puppetd start”<br>查看返回结果或日志显示success即说明服务全部启动</p>
<h3 id="检测服务">检测服务</h3><p>puppet网段客户端：<br>Pssh –h host.list –P –o log “puppetd –test –server puppet02.yourdomain.cn”<br>生产网段客户端：<br>Pssh –h host.list –P –o log “puppetd -t”<br>            查看返回结果或日志显示success</p>
<h1 id="日常操作说明">日常操作说明</h1><p>证书删除<br>服务器端执行puppet cert  list查看等待签名的客户端请求<br>服务器端执行puppet cert  list—all查看所有已签名的客户端<br>服务器端执行puppet cert clean test.yourdomain.cn删除已签名的客户端<br>客户端直接rm –rf /etc/puppet/ssl目录即可删除客户端证书<br>客户端执行puppetd –test –server puppet02.yourdomain.cn即可生成新证书并自动服务器签名<br>Module路径<br>Puppet 3.2.4版module默认路径位于/etc/puppet/environments/production/modules/下</p>
]]></content>
    <summary type="html">
    <![CDATA[通过foreman和puppet搭建自动化运维平台]]>
    
    </summary>
    
      <category term="linux" scheme="http://www.anste.com/tags/linux/"/>
    
      <category term="puppet" scheme="http://www.anste.com/tags/puppet/"/>
    
      <category term="Linux" scheme="http://www.anste.com/categories/Linux/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Hello World]]></title>
    <link href="http://www.anste.com/2015/06/09/hello-world/"/>
    <id>http://www.anste.com/2015/06/09/hello-world/</id>
    <published>2015-06-09T02:12:19.911Z</published>
    <updated>2015-06-08T12:21:32.000Z</updated>
    <content type="html"><![CDATA[<p>Welcome to <a href="http://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="http://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="http://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick_Start">Quick Start</h2><h3 id="Create_a_new_post">Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="http://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run_server">Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="http://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate_static_files">Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="http://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy_to_remote_sites">Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="http://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Welcome to <a href="http://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="http://hexo.io]]>
    </summary>
    
  </entry>
  
</feed>